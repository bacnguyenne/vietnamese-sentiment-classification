{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f94c436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:31:49.176345Z",
     "iopub.status.busy": "2024-10-16T11:31:49.175510Z",
     "iopub.status.idle": "2024-10-16T11:32:12.588141Z",
     "shell.execute_reply": "2024-10-16T11:32:12.587195Z"
    },
    "papermill": {
     "duration": 23.42039,
     "end_time": "2024-10-16T11:32:12.590718",
     "exception": false,
     "start_time": "2024-10-16T11:31:49.170328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vncorenlp\r\n",
      "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vncorenlp) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (2024.8.30)\r\n",
      "Building wheels for collected packages: vncorenlp\r\n",
      "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645932 sha256=c71757b2eb29ae7fdc8f7d9d63ef7a9b391096307dcfbf273fd28447a9be3dc6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/d9/b3/41f6c6b1ab758561fd4aab55dc0480b9d7a131c6aaa573a3fa\r\n",
      "Successfully built vncorenlp\r\n",
      "Installing collected packages: vncorenlp\r\n",
      "Successfully installed vncorenlp-1.0.3\r\n",
      "Cloning into 'VnCoreNLP'...\r\n",
      "remote: Enumerating objects: 259, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (47/47), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\r\n",
      "remote: Total 259 (delta 17), reused 33 (delta 11), pack-reused 212 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (259/259), 237.79 MiB | 49.71 MiB/s, done.\r\n",
      "Resolving deltas: 100% (93/93), done.\r\n"
     ]
    }
   ],
   "source": [
    "!pip install vncorenlp\n",
    "!git clone https://github.com/vncorenlp/VnCoreNLP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58bc3542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:32:12.604592Z",
     "iopub.status.busy": "2024-10-16T11:32:12.604281Z",
     "iopub.status.idle": "2024-10-16T11:32:24.215694Z",
     "shell.execute_reply": "2024-10-16T11:32:24.214543Z"
    },
    "papermill": {
     "duration": 11.620999,
     "end_time": "2024-10-16T11:32:24.218197",
     "exception": false,
     "start_time": "2024-10-16T11:32:12.597198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-16 11:32:13--  https://github.com/vncorenlp/VnCoreNLP/archive/refs/tags/v1.2.zip\r\n",
      "Resolving github.com (github.com)... 140.82.116.3\r\n",
      "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://codeload.github.com/vncorenlp/VnCoreNLP/zip/refs/tags/v1.2 [following]\r\n",
      "--2024-10-16 11:32:13--  https://codeload.github.com/vncorenlp/VnCoreNLP/zip/refs/tags/v1.2\r\n",
      "Resolving codeload.github.com (codeload.github.com)... 140.82.116.9\r\n",
      "Connecting to codeload.github.com (codeload.github.com)|140.82.116.9|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/zip]\r\n",
      "Saving to: 'v1.2.zip'\r\n",
      "\r\n",
      "v1.2.zip                [                 <=>] 160.83M  20.0MB/s    in 8.0s    \r\n",
      "\r\n",
      "2024-10-16 11:32:21 (20.0 MB/s) - 'v1.2.zip' saved [168648673]\r\n",
      "\r\n",
      "Archive:  v1.2.zip\r\n",
      "62bbc58fe5d113c898eae112656be97dcf50b3a0\r\n",
      "   creating: VnCoreNLP-1.2/\r\n",
      "  inflating: VnCoreNLP-1.2/LICENSE.md  \r\n",
      "  inflating: VnCoreNLP-1.2/Readme.md  \r\n",
      "  inflating: VnCoreNLP-1.2/TagsetDescription.md  \r\n",
      "  inflating: VnCoreNLP-1.2/VLSP2013_POS_tagset.pdf  \r\n",
      "  inflating: VnCoreNLP-1.2/VnCoreNLP-1.1.1.jar  \r\n",
      "  inflating: VnCoreNLP-1.2/VnCoreNLP-1.2.jar  \r\n",
      "  inflating: VnCoreNLP-1.2/VnDT-treebank-description.pdf  \r\n",
      "   creating: VnCoreNLP-1.2/models/\r\n",
      "   creating: VnCoreNLP-1.2/models/dep/\r\n",
      " extracting: VnCoreNLP-1.2/models/dep/vi-dep.xz  \r\n",
      "   creating: VnCoreNLP-1.2/models/ner/\r\n",
      " extracting: VnCoreNLP-1.2/models/ner/vi-500brownclusters.xz  \r\n",
      " extracting: VnCoreNLP-1.2/models/ner/vi-ner.xz  \r\n",
      " extracting: VnCoreNLP-1.2/models/ner/vi-pretrainedembeddings.xz  \r\n",
      "   creating: VnCoreNLP-1.2/models/postagger/\r\n",
      " extracting: VnCoreNLP-1.2/models/postagger/vi-tagger  \r\n",
      "   creating: VnCoreNLP-1.2/models/wordsegmenter/\r\n",
      "  inflating: VnCoreNLP-1.2/models/wordsegmenter/vi-vocab  \r\n",
      "  inflating: VnCoreNLP-1.2/models/wordsegmenter/wordsegmenter.rdr  \r\n",
      "  inflating: VnCoreNLP-1.2/pom.xml   \r\n",
      "   creating: VnCoreNLP-1.2/src/\r\n",
      "   creating: VnCoreNLP-1.2/src/main/\r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/\r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/\r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/corenlp/\r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/corenlp/ner/\r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/ner/NerRecognizer.java  \r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/corenlp/parser/\r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/parser/DependencyParser.java  \r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/corenlp/postagger/\r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/postagger/PosTagger.java  \r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/corenlp/tokenizer/\r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/tokenizer/StringUtils.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/tokenizer/Tokenizer.java  \r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/corenlp/wordsegmenter/\r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/wordsegmenter/FWObject.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/wordsegmenter/Node.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/wordsegmenter/Utils.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/wordsegmenter/Vocabulary.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/wordsegmenter/WordSegmenter.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/corenlp/wordsegmenter/WordTag.java  \r\n",
      "   creating: VnCoreNLP-1.2/src/main/java/vn/pipeline/\r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/pipeline/Annotation.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/pipeline/LexicalInitializer.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/pipeline/Sentence.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/pipeline/Utils.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/pipeline/VnCoreNLP.java  \r\n",
      "  inflating: VnCoreNLP-1.2/src/main/java/vn/pipeline/Word.java  \r\n",
      "   creating: VnCoreNLP-1.2/src/main/resources/\r\n",
      "  inflating: VnCoreNLP-1.2/src/main/resources/log4j.properties  \r\n",
      "   creating: VnCoreNLP-1.2/src/test/\r\n",
      "   creating: VnCoreNLP-1.2/src/test/java/\r\n",
      "  inflating: VnCoreNLP-1.2/src/test/java/VnCoreNLPExample.java  \r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/vncorenlp/VnCoreNLP/archive/refs/tags/v1.2.zip\n",
    "!unzip v1.2.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59fde67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:32:24.236224Z",
     "iopub.status.busy": "2024-10-16T11:32:24.235840Z",
     "iopub.status.idle": "2024-10-16T11:32:54.714060Z",
     "shell.execute_reply": "2024-10-16T11:32:54.713178Z"
    },
    "papermill": {
     "duration": 30.490029,
     "end_time": "2024-10-16T11:32:54.716644",
     "exception": false,
     "start_time": "2024-10-16T11:32:24.226615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "import os\n",
    "\n",
    "# Khởi động VnCoreNLP\n",
    "rdrsegmenter = VnCoreNLP(os.path.join(\"/kaggle/working/VnCoreNLP-1.2/VnCoreNLP-1.2.jar\"), annotators=\"wseg,pos,ner,parse\", max_heap_size='-Xmx2g')\n",
    "\n",
    "# Hàm tách từ sử dụng VnCoreNLP\n",
    "def word_segment(text):\n",
    "    return ' '.join(rdrsegmenter.tokenize(text)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897f43be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:32:54.735954Z",
     "iopub.status.busy": "2024-10-16T11:32:54.735648Z",
     "iopub.status.idle": "2024-10-16T11:35:56.426840Z",
     "shell.execute_reply": "2024-10-16T11:35:56.425720Z"
    },
    "papermill": {
     "duration": 181.704031,
     "end_time": "2024-10-16T11:35:56.429203",
     "exception": false,
     "start_time": "2024-10-16T11:32:54.725172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb39d18dbdaf41c1acfcfe26601fa443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "data = pd.read_csv('/kaggle/input/data-dl-tk2/df_final_a.csv')\n",
    "data = data.dropna().reset_index()\n",
    "data['cleaned_segmented'] = data['cleaned_old_data'].progress_apply(word_segment)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_segmented'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Chuyển đổi văn bản thành vector TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650e8a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:35:56.447761Z",
     "iopub.status.busy": "2024-10-16T11:35:56.447434Z",
     "iopub.status.idle": "2024-10-16T11:35:56.490214Z",
     "shell.execute_reply": "2024-10-16T11:35:56.489161Z"
    },
    "papermill": {
     "duration": 0.054314,
     "end_time": "2024-10-16T11:35:56.492367",
     "exception": false,
     "start_time": "2024-10-16T11:35:56.438053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66      2380\n",
      "           1       0.71      0.71      0.71      2315\n",
      "           2       0.56      0.55      0.55      2415\n",
      "           3       0.72      0.63      0.67      2416\n",
      "           4       0.71      0.66      0.69      2257\n",
      "           5       0.71      0.81      0.76      2442\n",
      "\n",
      "    accuracy                           0.67     14225\n",
      "   macro avg       0.67      0.67      0.67     14225\n",
      "weighted avg       0.67      0.67      0.67     14225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18631fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:35:56.510756Z",
     "iopub.status.busy": "2024-10-16T11:35:56.510427Z",
     "iopub.status.idle": "2024-10-16T11:36:04.153672Z",
     "shell.execute_reply": "2024-10-16T11:36:04.152688Z"
    },
    "papermill": {
     "duration": 7.654869,
     "end_time": "2024-10-16T11:36:04.155889",
     "exception": false,
     "start_time": "2024-10-16T11:35:56.501020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7534    0.7433    0.7483      2380\n",
      "           1     0.7396    0.7814    0.7599      2315\n",
      "           2     0.6967    0.6497    0.6724      2415\n",
      "           3     0.8180    0.8353    0.8265      2416\n",
      "           4     0.8244    0.7944    0.8091      2257\n",
      "           5     0.9022    0.9373    0.9195      2442\n",
      "\n",
      "    accuracy                         0.7907     14225\n",
      "   macro avg     0.7891    0.7902    0.7893     14225\n",
      "weighted avg     0.7893    0.7907    0.7896     14225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Dự đoán và đánh giá mô hình\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e884d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:36:04.174593Z",
     "iopub.status.busy": "2024-10-16T11:36:04.174255Z",
     "iopub.status.idle": "2024-10-16T11:37:07.875084Z",
     "shell.execute_reply": "2024-10-16T11:37:07.874072Z"
    },
    "papermill": {
     "duration": 63.721274,
     "end_time": "2024-10-16T11:37:07.886016",
     "exception": false,
     "start_time": "2024-10-16T11:36:04.164742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7856    0.7912    0.7884      2380\n",
      "           1     0.7100    0.7624    0.7353      2315\n",
      "           2     0.7427    0.6944    0.7177      2415\n",
      "           3     0.8962    0.8965    0.8963      2416\n",
      "           4     0.8460    0.8299    0.8378      2257\n",
      "           5     0.9649    0.9693    0.9671      2442\n",
      "\n",
      "    accuracy                         0.8247     14225\n",
      "   macro avg     0.8242    0.8239    0.8238     14225\n",
      "weighted avg     0.8251    0.8247    0.8246     14225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Chuyển đổi nhãn thành mảng numpy\n",
    "y_train_np = y_train.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# Tạo DMatrix cho XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_tfidf, label=y_train_np)\n",
    "dtest = xgb.DMatrix(X_test_tfidf, label=y_test_np)\n",
    "\n",
    "# Thiết lập tham số cho XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 6,\n",
    "    'eval_metric': 'merror',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Dự đoán\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "222f364c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T11:37:07.905386Z",
     "iopub.status.busy": "2024-10-16T11:37:07.905074Z",
     "iopub.status.idle": "2024-10-16T15:16:25.141813Z",
     "shell.execute_reply": "2024-10-16T15:16:25.140731Z"
    },
    "papermill": {
     "duration": 13157.394756,
     "end_time": "2024-10-16T15:16:25.289849",
     "exception": false,
     "start_time": "2024-10-16T11:37:07.895093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng thiết bị: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e7a188520b4115baada1433ae899f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf63eac022d04733965950cbbd02d7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650052d47a9f49fa8f2c237ad93a7774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cc36ead60d41b6a5e15f15da36bfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abc1a066c784e83b3b175fecdd6169b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu mã hóa dữ liệu...\n",
      "Hoàn tất mã hóa dữ liệu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu huấn luyện mô hình...\n",
      "\n",
      "===== Epoch 1 / 10 =====\n",
      "  Batch 10/1778 - Loss: 1.7766, Accuracy: 0.2159\n",
      "  Batch 20/1778 - Loss: 1.7635, Accuracy: 0.2396\n",
      "  Batch 30/1778 - Loss: 1.7550, Accuracy: 0.2530\n",
      "  Batch 40/1778 - Loss: 1.7392, Accuracy: 0.2805\n",
      "  Batch 50/1778 - Loss: 1.7254, Accuracy: 0.2972\n",
      "  Batch 60/1778 - Loss: 1.7108, Accuracy: 0.3161\n",
      "  Batch 70/1778 - Loss: 1.6928, Accuracy: 0.3354\n",
      "  Batch 80/1778 - Loss: 1.6740, Accuracy: 0.3503\n",
      "  Batch 90/1778 - Loss: 1.6605, Accuracy: 0.3565\n",
      "  Batch 100/1778 - Loss: 1.6445, Accuracy: 0.3642\n",
      "  Batch 110/1778 - Loss: 1.6247, Accuracy: 0.3767\n",
      "  Batch 120/1778 - Loss: 1.6043, Accuracy: 0.3905\n",
      "  Batch 130/1778 - Loss: 1.5828, Accuracy: 0.4031\n",
      "  Batch 140/1778 - Loss: 1.5639, Accuracy: 0.4125\n",
      "  Batch 150/1778 - Loss: 1.5483, Accuracy: 0.4180\n",
      "  Batch 160/1778 - Loss: 1.5302, Accuracy: 0.4274\n",
      "  Batch 170/1778 - Loss: 1.5137, Accuracy: 0.4344\n",
      "  Batch 180/1778 - Loss: 1.4961, Accuracy: 0.4406\n",
      "  Batch 190/1778 - Loss: 1.4854, Accuracy: 0.4455\n",
      "  Batch 200/1778 - Loss: 1.4724, Accuracy: 0.4493\n",
      "  Batch 210/1778 - Loss: 1.4586, Accuracy: 0.4562\n",
      "  Batch 220/1778 - Loss: 1.4485, Accuracy: 0.4622\n",
      "  Batch 230/1778 - Loss: 1.4350, Accuracy: 0.4675\n",
      "  Batch 240/1778 - Loss: 1.4253, Accuracy: 0.4706\n",
      "  Batch 250/1778 - Loss: 1.4159, Accuracy: 0.4735\n",
      "  Batch 260/1778 - Loss: 1.4061, Accuracy: 0.4776\n",
      "  Batch 270/1778 - Loss: 1.3986, Accuracy: 0.4797\n",
      "  Batch 280/1778 - Loss: 1.3906, Accuracy: 0.4834\n",
      "  Batch 290/1778 - Loss: 1.3822, Accuracy: 0.4866\n",
      "  Batch 300/1778 - Loss: 1.3720, Accuracy: 0.4903\n",
      "  Batch 310/1778 - Loss: 1.3627, Accuracy: 0.4934\n",
      "  Batch 320/1778 - Loss: 1.3533, Accuracy: 0.4976\n",
      "  Batch 330/1778 - Loss: 1.3440, Accuracy: 0.5025\n",
      "  Batch 340/1778 - Loss: 1.3349, Accuracy: 0.5066\n",
      "  Batch 350/1778 - Loss: 1.3269, Accuracy: 0.5095\n",
      "  Batch 360/1778 - Loss: 1.3180, Accuracy: 0.5136\n",
      "  Batch 370/1778 - Loss: 1.3120, Accuracy: 0.5159\n",
      "  Batch 380/1778 - Loss: 1.3030, Accuracy: 0.5195\n",
      "  Batch 390/1778 - Loss: 1.2944, Accuracy: 0.5230\n",
      "  Batch 400/1778 - Loss: 1.2881, Accuracy: 0.5251\n",
      "  Batch 410/1778 - Loss: 1.2806, Accuracy: 0.5281\n",
      "  Batch 420/1778 - Loss: 1.2749, Accuracy: 0.5306\n",
      "  Batch 430/1778 - Loss: 1.2677, Accuracy: 0.5326\n",
      "  Batch 440/1778 - Loss: 1.2617, Accuracy: 0.5348\n",
      "  Batch 450/1778 - Loss: 1.2542, Accuracy: 0.5382\n",
      "  Batch 460/1778 - Loss: 1.2471, Accuracy: 0.5406\n",
      "  Batch 470/1778 - Loss: 1.2421, Accuracy: 0.5426\n",
      "  Batch 480/1778 - Loss: 1.2350, Accuracy: 0.5453\n",
      "  Batch 490/1778 - Loss: 1.2291, Accuracy: 0.5474\n",
      "  Batch 500/1778 - Loss: 1.2246, Accuracy: 0.5492\n",
      "  Batch 510/1778 - Loss: 1.2176, Accuracy: 0.5524\n",
      "  Batch 520/1778 - Loss: 1.2095, Accuracy: 0.5558\n",
      "  Batch 530/1778 - Loss: 1.2045, Accuracy: 0.5583\n",
      "  Batch 540/1778 - Loss: 1.1979, Accuracy: 0.5609\n",
      "  Batch 550/1778 - Loss: 1.1931, Accuracy: 0.5628\n",
      "  Batch 560/1778 - Loss: 1.1888, Accuracy: 0.5643\n",
      "  Batch 570/1778 - Loss: 1.1847, Accuracy: 0.5659\n",
      "  Batch 580/1778 - Loss: 1.1802, Accuracy: 0.5677\n",
      "  Batch 590/1778 - Loss: 1.1744, Accuracy: 0.5702\n",
      "  Batch 600/1778 - Loss: 1.1709, Accuracy: 0.5713\n",
      "  Batch 610/1778 - Loss: 1.1661, Accuracy: 0.5732\n",
      "  Batch 620/1778 - Loss: 1.1628, Accuracy: 0.5747\n",
      "  Batch 630/1778 - Loss: 1.1582, Accuracy: 0.5766\n",
      "  Batch 640/1778 - Loss: 1.1535, Accuracy: 0.5785\n",
      "  Batch 650/1778 - Loss: 1.1485, Accuracy: 0.5803\n",
      "  Batch 660/1778 - Loss: 1.1448, Accuracy: 0.5819\n",
      "  Batch 670/1778 - Loss: 1.1424, Accuracy: 0.5828\n",
      "  Batch 680/1778 - Loss: 1.1387, Accuracy: 0.5843\n",
      "  Batch 690/1778 - Loss: 1.1349, Accuracy: 0.5858\n",
      "  Batch 700/1778 - Loss: 1.1314, Accuracy: 0.5868\n",
      "  Batch 710/1778 - Loss: 1.1264, Accuracy: 0.5888\n",
      "  Batch 720/1778 - Loss: 1.1224, Accuracy: 0.5905\n",
      "  Batch 730/1778 - Loss: 1.1179, Accuracy: 0.5925\n",
      "  Batch 740/1778 - Loss: 1.1151, Accuracy: 0.5933\n",
      "  Batch 750/1778 - Loss: 1.1113, Accuracy: 0.5948\n",
      "  Batch 760/1778 - Loss: 1.1070, Accuracy: 0.5966\n",
      "  Batch 770/1778 - Loss: 1.1038, Accuracy: 0.5978\n",
      "  Batch 780/1778 - Loss: 1.0998, Accuracy: 0.5997\n",
      "  Batch 790/1778 - Loss: 1.0970, Accuracy: 0.6005\n",
      "  Batch 800/1778 - Loss: 1.0941, Accuracy: 0.6016\n",
      "  Batch 810/1778 - Loss: 1.0919, Accuracy: 0.6023\n",
      "  Batch 820/1778 - Loss: 1.0887, Accuracy: 0.6033\n",
      "  Batch 830/1778 - Loss: 1.0853, Accuracy: 0.6045\n",
      "  Batch 840/1778 - Loss: 1.0811, Accuracy: 0.6061\n",
      "  Batch 850/1778 - Loss: 1.0782, Accuracy: 0.6074\n",
      "  Batch 860/1778 - Loss: 1.0742, Accuracy: 0.6090\n",
      "  Batch 870/1778 - Loss: 1.0710, Accuracy: 0.6100\n",
      "  Batch 880/1778 - Loss: 1.0669, Accuracy: 0.6114\n",
      "  Batch 890/1778 - Loss: 1.0641, Accuracy: 0.6122\n",
      "  Batch 900/1778 - Loss: 1.0612, Accuracy: 0.6130\n",
      "  Batch 910/1778 - Loss: 1.0592, Accuracy: 0.6140\n",
      "  Batch 920/1778 - Loss: 1.0561, Accuracy: 0.6151\n",
      "  Batch 930/1778 - Loss: 1.0535, Accuracy: 0.6161\n",
      "  Batch 940/1778 - Loss: 1.0517, Accuracy: 0.6168\n",
      "  Batch 950/1778 - Loss: 1.0483, Accuracy: 0.6182\n",
      "  Batch 960/1778 - Loss: 1.0451, Accuracy: 0.6193\n",
      "  Batch 970/1778 - Loss: 1.0419, Accuracy: 0.6206\n",
      "  Batch 980/1778 - Loss: 1.0395, Accuracy: 0.6216\n",
      "  Batch 990/1778 - Loss: 1.0369, Accuracy: 0.6224\n",
      "  Batch 1000/1778 - Loss: 1.0338, Accuracy: 0.6234\n",
      "  Batch 1010/1778 - Loss: 1.0313, Accuracy: 0.6242\n",
      "  Batch 1020/1778 - Loss: 1.0284, Accuracy: 0.6250\n",
      "  Batch 1030/1778 - Loss: 1.0251, Accuracy: 0.6263\n",
      "  Batch 1040/1778 - Loss: 1.0226, Accuracy: 0.6274\n",
      "  Batch 1050/1778 - Loss: 1.0207, Accuracy: 0.6283\n",
      "  Batch 1060/1778 - Loss: 1.0178, Accuracy: 0.6294\n",
      "  Batch 1070/1778 - Loss: 1.0153, Accuracy: 0.6303\n",
      "  Batch 1080/1778 - Loss: 1.0137, Accuracy: 0.6310\n",
      "  Batch 1090/1778 - Loss: 1.0117, Accuracy: 0.6318\n",
      "  Batch 1100/1778 - Loss: 1.0095, Accuracy: 0.6326\n",
      "  Batch 1110/1778 - Loss: 1.0070, Accuracy: 0.6337\n",
      "  Batch 1120/1778 - Loss: 1.0046, Accuracy: 0.6347\n",
      "  Batch 1130/1778 - Loss: 1.0020, Accuracy: 0.6357\n",
      "  Batch 1140/1778 - Loss: 1.0001, Accuracy: 0.6364\n",
      "  Batch 1150/1778 - Loss: 0.9971, Accuracy: 0.6376\n",
      "  Batch 1160/1778 - Loss: 0.9955, Accuracy: 0.6382\n",
      "  Batch 1170/1778 - Loss: 0.9936, Accuracy: 0.6391\n",
      "  Batch 1180/1778 - Loss: 0.9917, Accuracy: 0.6397\n",
      "  Batch 1190/1778 - Loss: 0.9891, Accuracy: 0.6406\n",
      "  Batch 1200/1778 - Loss: 0.9871, Accuracy: 0.6412\n",
      "  Batch 1210/1778 - Loss: 0.9847, Accuracy: 0.6421\n",
      "  Batch 1220/1778 - Loss: 0.9826, Accuracy: 0.6429\n",
      "  Batch 1230/1778 - Loss: 0.9804, Accuracy: 0.6437\n",
      "  Batch 1240/1778 - Loss: 0.9777, Accuracy: 0.6448\n",
      "  Batch 1250/1778 - Loss: 0.9753, Accuracy: 0.6457\n",
      "  Batch 1260/1778 - Loss: 0.9732, Accuracy: 0.6466\n",
      "  Batch 1270/1778 - Loss: 0.9719, Accuracy: 0.6471\n",
      "  Batch 1280/1778 - Loss: 0.9693, Accuracy: 0.6482\n",
      "  Batch 1290/1778 - Loss: 0.9672, Accuracy: 0.6491\n",
      "  Batch 1300/1778 - Loss: 0.9652, Accuracy: 0.6498\n",
      "  Batch 1310/1778 - Loss: 0.9634, Accuracy: 0.6506\n",
      "  Batch 1320/1778 - Loss: 0.9619, Accuracy: 0.6510\n",
      "  Batch 1330/1778 - Loss: 0.9595, Accuracy: 0.6519\n",
      "  Batch 1340/1778 - Loss: 0.9578, Accuracy: 0.6525\n",
      "  Batch 1350/1778 - Loss: 0.9557, Accuracy: 0.6532\n",
      "  Batch 1360/1778 - Loss: 0.9535, Accuracy: 0.6541\n",
      "  Batch 1370/1778 - Loss: 0.9519, Accuracy: 0.6546\n",
      "  Batch 1380/1778 - Loss: 0.9499, Accuracy: 0.6554\n",
      "  Batch 1390/1778 - Loss: 0.9484, Accuracy: 0.6560\n",
      "  Batch 1400/1778 - Loss: 0.9463, Accuracy: 0.6567\n",
      "  Batch 1410/1778 - Loss: 0.9445, Accuracy: 0.6575\n",
      "  Batch 1420/1778 - Loss: 0.9426, Accuracy: 0.6583\n",
      "  Batch 1430/1778 - Loss: 0.9407, Accuracy: 0.6589\n",
      "  Batch 1440/1778 - Loss: 0.9395, Accuracy: 0.6593\n",
      "  Batch 1450/1778 - Loss: 0.9369, Accuracy: 0.6604\n",
      "  Batch 1460/1778 - Loss: 0.9352, Accuracy: 0.6609\n",
      "  Batch 1470/1778 - Loss: 0.9334, Accuracy: 0.6615\n",
      "  Batch 1480/1778 - Loss: 0.9318, Accuracy: 0.6618\n",
      "  Batch 1490/1778 - Loss: 0.9300, Accuracy: 0.6625\n",
      "  Batch 1500/1778 - Loss: 0.9289, Accuracy: 0.6629\n",
      "  Batch 1510/1778 - Loss: 0.9275, Accuracy: 0.6634\n",
      "  Batch 1520/1778 - Loss: 0.9254, Accuracy: 0.6642\n",
      "  Batch 1530/1778 - Loss: 0.9238, Accuracy: 0.6648\n",
      "  Batch 1540/1778 - Loss: 0.9219, Accuracy: 0.6655\n",
      "  Batch 1550/1778 - Loss: 0.9204, Accuracy: 0.6660\n",
      "  Batch 1560/1778 - Loss: 0.9185, Accuracy: 0.6667\n",
      "  Batch 1570/1778 - Loss: 0.9167, Accuracy: 0.6673\n",
      "  Batch 1580/1778 - Loss: 0.9155, Accuracy: 0.6677\n",
      "  Batch 1590/1778 - Loss: 0.9133, Accuracy: 0.6684\n",
      "  Batch 1600/1778 - Loss: 0.9115, Accuracy: 0.6691\n",
      "  Batch 1610/1778 - Loss: 0.9098, Accuracy: 0.6699\n",
      "  Batch 1620/1778 - Loss: 0.9086, Accuracy: 0.6704\n",
      "  Batch 1630/1778 - Loss: 0.9072, Accuracy: 0.6709\n",
      "  Batch 1640/1778 - Loss: 0.9053, Accuracy: 0.6717\n",
      "  Batch 1650/1778 - Loss: 0.9038, Accuracy: 0.6725\n",
      "  Batch 1660/1778 - Loss: 0.9014, Accuracy: 0.6734\n",
      "  Batch 1670/1778 - Loss: 0.8996, Accuracy: 0.6741\n",
      "  Batch 1680/1778 - Loss: 0.8976, Accuracy: 0.6749\n",
      "  Batch 1690/1778 - Loss: 0.8959, Accuracy: 0.6755\n",
      "  Batch 1700/1778 - Loss: 0.8944, Accuracy: 0.6760\n",
      "  Batch 1710/1778 - Loss: 0.8932, Accuracy: 0.6764\n",
      "  Batch 1720/1778 - Loss: 0.8916, Accuracy: 0.6769\n",
      "  Batch 1730/1778 - Loss: 0.8898, Accuracy: 0.6776\n",
      "  Batch 1740/1778 - Loss: 0.8884, Accuracy: 0.6782\n",
      "  Batch 1750/1778 - Loss: 0.8868, Accuracy: 0.6787\n",
      "  Batch 1760/1778 - Loss: 0.8855, Accuracy: 0.6792\n",
      "  Batch 1770/1778 - Loss: 0.8842, Accuracy: 0.6797\n",
      "\n",
      "Kết quả Epoch 1:\n",
      "  Loss trung bình: 0.8832\n",
      "  Độ chính xác trung bình: 0.6801\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 2 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.5810, Accuracy: 0.7869\n",
      "  Batch 20/1778 - Loss: 0.5964, Accuracy: 0.7783\n",
      "  Batch 30/1778 - Loss: 0.6019, Accuracy: 0.7833\n",
      "  Batch 40/1778 - Loss: 0.5924, Accuracy: 0.7881\n",
      "  Batch 50/1778 - Loss: 0.5892, Accuracy: 0.7892\n",
      "  Batch 60/1778 - Loss: 0.5873, Accuracy: 0.7853\n",
      "  Batch 70/1778 - Loss: 0.5866, Accuracy: 0.7848\n",
      "  Batch 80/1778 - Loss: 0.5774, Accuracy: 0.7863\n",
      "  Batch 90/1778 - Loss: 0.5705, Accuracy: 0.7874\n",
      "  Batch 100/1778 - Loss: 0.5737, Accuracy: 0.7865\n",
      "  Batch 110/1778 - Loss: 0.5770, Accuracy: 0.7855\n",
      "  Batch 120/1778 - Loss: 0.5803, Accuracy: 0.7836\n",
      "  Batch 130/1778 - Loss: 0.5778, Accuracy: 0.7851\n",
      "  Batch 140/1778 - Loss: 0.5755, Accuracy: 0.7855\n",
      "  Batch 150/1778 - Loss: 0.5764, Accuracy: 0.7856\n",
      "  Batch 160/1778 - Loss: 0.5809, Accuracy: 0.7845\n",
      "  Batch 170/1778 - Loss: 0.5836, Accuracy: 0.7836\n",
      "  Batch 180/1778 - Loss: 0.5859, Accuracy: 0.7830\n",
      "  Batch 190/1778 - Loss: 0.5840, Accuracy: 0.7835\n",
      "  Batch 200/1778 - Loss: 0.5828, Accuracy: 0.7844\n",
      "  Batch 210/1778 - Loss: 0.5837, Accuracy: 0.7839\n",
      "  Batch 220/1778 - Loss: 0.5831, Accuracy: 0.7841\n",
      "  Batch 230/1778 - Loss: 0.5800, Accuracy: 0.7846\n",
      "  Batch 240/1778 - Loss: 0.5770, Accuracy: 0.7867\n",
      "  Batch 250/1778 - Loss: 0.5769, Accuracy: 0.7866\n",
      "  Batch 260/1778 - Loss: 0.5756, Accuracy: 0.7871\n",
      "  Batch 270/1778 - Loss: 0.5726, Accuracy: 0.7883\n",
      "  Batch 280/1778 - Loss: 0.5694, Accuracy: 0.7900\n",
      "  Batch 290/1778 - Loss: 0.5679, Accuracy: 0.7898\n",
      "  Batch 300/1778 - Loss: 0.5687, Accuracy: 0.7903\n",
      "  Batch 310/1778 - Loss: 0.5688, Accuracy: 0.7902\n",
      "  Batch 320/1778 - Loss: 0.5692, Accuracy: 0.7891\n",
      "  Batch 330/1778 - Loss: 0.5707, Accuracy: 0.7887\n",
      "  Batch 340/1778 - Loss: 0.5709, Accuracy: 0.7889\n",
      "  Batch 350/1778 - Loss: 0.5722, Accuracy: 0.7881\n",
      "  Batch 360/1778 - Loss: 0.5699, Accuracy: 0.7893\n",
      "  Batch 370/1778 - Loss: 0.5676, Accuracy: 0.7906\n",
      "  Batch 380/1778 - Loss: 0.5670, Accuracy: 0.7906\n",
      "  Batch 390/1778 - Loss: 0.5637, Accuracy: 0.7920\n",
      "  Batch 400/1778 - Loss: 0.5640, Accuracy: 0.7915\n",
      "  Batch 410/1778 - Loss: 0.5641, Accuracy: 0.7915\n",
      "  Batch 420/1778 - Loss: 0.5625, Accuracy: 0.7921\n",
      "  Batch 430/1778 - Loss: 0.5619, Accuracy: 0.7921\n",
      "  Batch 440/1778 - Loss: 0.5619, Accuracy: 0.7918\n",
      "  Batch 450/1778 - Loss: 0.5631, Accuracy: 0.7913\n",
      "  Batch 460/1778 - Loss: 0.5627, Accuracy: 0.7913\n",
      "  Batch 470/1778 - Loss: 0.5611, Accuracy: 0.7921\n",
      "  Batch 480/1778 - Loss: 0.5615, Accuracy: 0.7917\n",
      "  Batch 490/1778 - Loss: 0.5615, Accuracy: 0.7915\n",
      "  Batch 500/1778 - Loss: 0.5613, Accuracy: 0.7912\n",
      "  Batch 510/1778 - Loss: 0.5609, Accuracy: 0.7912\n",
      "  Batch 520/1778 - Loss: 0.5612, Accuracy: 0.7910\n",
      "  Batch 530/1778 - Loss: 0.5614, Accuracy: 0.7907\n",
      "  Batch 540/1778 - Loss: 0.5617, Accuracy: 0.7908\n",
      "  Batch 550/1778 - Loss: 0.5623, Accuracy: 0.7905\n",
      "  Batch 560/1778 - Loss: 0.5626, Accuracy: 0.7903\n",
      "  Batch 570/1778 - Loss: 0.5619, Accuracy: 0.7908\n",
      "  Batch 580/1778 - Loss: 0.5621, Accuracy: 0.7912\n",
      "  Batch 590/1778 - Loss: 0.5620, Accuracy: 0.7911\n",
      "  Batch 600/1778 - Loss: 0.5619, Accuracy: 0.7909\n",
      "  Batch 610/1778 - Loss: 0.5612, Accuracy: 0.7911\n",
      "  Batch 620/1778 - Loss: 0.5618, Accuracy: 0.7909\n",
      "  Batch 630/1778 - Loss: 0.5612, Accuracy: 0.7916\n",
      "  Batch 640/1778 - Loss: 0.5600, Accuracy: 0.7919\n",
      "  Batch 650/1778 - Loss: 0.5598, Accuracy: 0.7920\n",
      "  Batch 660/1778 - Loss: 0.5593, Accuracy: 0.7925\n",
      "  Batch 670/1778 - Loss: 0.5585, Accuracy: 0.7925\n",
      "  Batch 680/1778 - Loss: 0.5590, Accuracy: 0.7924\n",
      "  Batch 690/1778 - Loss: 0.5585, Accuracy: 0.7925\n",
      "  Batch 700/1778 - Loss: 0.5598, Accuracy: 0.7919\n",
      "  Batch 710/1778 - Loss: 0.5582, Accuracy: 0.7926\n",
      "  Batch 720/1778 - Loss: 0.5579, Accuracy: 0.7930\n",
      "  Batch 730/1778 - Loss: 0.5559, Accuracy: 0.7942\n",
      "  Batch 740/1778 - Loss: 0.5552, Accuracy: 0.7944\n",
      "  Batch 750/1778 - Loss: 0.5541, Accuracy: 0.7949\n",
      "  Batch 760/1778 - Loss: 0.5543, Accuracy: 0.7951\n",
      "  Batch 770/1778 - Loss: 0.5539, Accuracy: 0.7954\n",
      "  Batch 780/1778 - Loss: 0.5544, Accuracy: 0.7951\n",
      "  Batch 790/1778 - Loss: 0.5551, Accuracy: 0.7950\n",
      "  Batch 800/1778 - Loss: 0.5543, Accuracy: 0.7951\n",
      "  Batch 810/1778 - Loss: 0.5547, Accuracy: 0.7950\n",
      "  Batch 820/1778 - Loss: 0.5551, Accuracy: 0.7950\n",
      "  Batch 830/1778 - Loss: 0.5546, Accuracy: 0.7952\n",
      "  Batch 840/1778 - Loss: 0.5546, Accuracy: 0.7952\n",
      "  Batch 850/1778 - Loss: 0.5538, Accuracy: 0.7952\n",
      "  Batch 860/1778 - Loss: 0.5542, Accuracy: 0.7951\n",
      "  Batch 870/1778 - Loss: 0.5537, Accuracy: 0.7956\n",
      "  Batch 880/1778 - Loss: 0.5537, Accuracy: 0.7952\n",
      "  Batch 890/1778 - Loss: 0.5545, Accuracy: 0.7948\n",
      "  Batch 900/1778 - Loss: 0.5536, Accuracy: 0.7951\n",
      "  Batch 910/1778 - Loss: 0.5541, Accuracy: 0.7949\n",
      "  Batch 920/1778 - Loss: 0.5540, Accuracy: 0.7950\n",
      "  Batch 930/1778 - Loss: 0.5532, Accuracy: 0.7952\n",
      "  Batch 940/1778 - Loss: 0.5531, Accuracy: 0.7955\n",
      "  Batch 950/1778 - Loss: 0.5534, Accuracy: 0.7957\n",
      "  Batch 960/1778 - Loss: 0.5534, Accuracy: 0.7958\n",
      "  Batch 970/1778 - Loss: 0.5535, Accuracy: 0.7958\n",
      "  Batch 980/1778 - Loss: 0.5528, Accuracy: 0.7961\n",
      "  Batch 990/1778 - Loss: 0.5530, Accuracy: 0.7960\n",
      "  Batch 1000/1778 - Loss: 0.5517, Accuracy: 0.7965\n",
      "  Batch 1010/1778 - Loss: 0.5515, Accuracy: 0.7966\n",
      "  Batch 1020/1778 - Loss: 0.5513, Accuracy: 0.7967\n",
      "  Batch 1030/1778 - Loss: 0.5515, Accuracy: 0.7965\n",
      "  Batch 1040/1778 - Loss: 0.5511, Accuracy: 0.7967\n",
      "  Batch 1050/1778 - Loss: 0.5504, Accuracy: 0.7969\n",
      "  Batch 1060/1778 - Loss: 0.5497, Accuracy: 0.7973\n",
      "  Batch 1070/1778 - Loss: 0.5491, Accuracy: 0.7976\n",
      "  Batch 1080/1778 - Loss: 0.5490, Accuracy: 0.7977\n",
      "  Batch 1090/1778 - Loss: 0.5483, Accuracy: 0.7979\n",
      "  Batch 1100/1778 - Loss: 0.5480, Accuracy: 0.7981\n",
      "  Batch 1110/1778 - Loss: 0.5478, Accuracy: 0.7986\n",
      "  Batch 1120/1778 - Loss: 0.5482, Accuracy: 0.7986\n",
      "  Batch 1130/1778 - Loss: 0.5478, Accuracy: 0.7986\n",
      "  Batch 1140/1778 - Loss: 0.5478, Accuracy: 0.7988\n",
      "  Batch 1150/1778 - Loss: 0.5480, Accuracy: 0.7987\n",
      "  Batch 1160/1778 - Loss: 0.5478, Accuracy: 0.7986\n",
      "  Batch 1170/1778 - Loss: 0.5476, Accuracy: 0.7987\n",
      "  Batch 1180/1778 - Loss: 0.5475, Accuracy: 0.7988\n",
      "  Batch 1190/1778 - Loss: 0.5476, Accuracy: 0.7988\n",
      "  Batch 1200/1778 - Loss: 0.5469, Accuracy: 0.7991\n",
      "  Batch 1210/1778 - Loss: 0.5472, Accuracy: 0.7989\n",
      "  Batch 1220/1778 - Loss: 0.5470, Accuracy: 0.7991\n",
      "  Batch 1230/1778 - Loss: 0.5465, Accuracy: 0.7992\n",
      "  Batch 1240/1778 - Loss: 0.5461, Accuracy: 0.7993\n",
      "  Batch 1250/1778 - Loss: 0.5453, Accuracy: 0.7998\n",
      "  Batch 1260/1778 - Loss: 0.5452, Accuracy: 0.7998\n",
      "  Batch 1270/1778 - Loss: 0.5448, Accuracy: 0.7997\n",
      "  Batch 1280/1778 - Loss: 0.5443, Accuracy: 0.7999\n",
      "  Batch 1290/1778 - Loss: 0.5452, Accuracy: 0.7996\n",
      "  Batch 1300/1778 - Loss: 0.5448, Accuracy: 0.7997\n",
      "  Batch 1310/1778 - Loss: 0.5442, Accuracy: 0.7998\n",
      "  Batch 1320/1778 - Loss: 0.5436, Accuracy: 0.8001\n",
      "  Batch 1330/1778 - Loss: 0.5433, Accuracy: 0.8002\n",
      "  Batch 1340/1778 - Loss: 0.5428, Accuracy: 0.8004\n",
      "  Batch 1350/1778 - Loss: 0.5420, Accuracy: 0.8007\n",
      "  Batch 1360/1778 - Loss: 0.5414, Accuracy: 0.8011\n",
      "  Batch 1370/1778 - Loss: 0.5410, Accuracy: 0.8012\n",
      "  Batch 1380/1778 - Loss: 0.5413, Accuracy: 0.8012\n",
      "  Batch 1390/1778 - Loss: 0.5412, Accuracy: 0.8013\n",
      "  Batch 1400/1778 - Loss: 0.5412, Accuracy: 0.8012\n",
      "  Batch 1410/1778 - Loss: 0.5409, Accuracy: 0.8014\n",
      "  Batch 1420/1778 - Loss: 0.5401, Accuracy: 0.8017\n",
      "  Batch 1430/1778 - Loss: 0.5398, Accuracy: 0.8017\n",
      "  Batch 1440/1778 - Loss: 0.5400, Accuracy: 0.8015\n",
      "  Batch 1450/1778 - Loss: 0.5394, Accuracy: 0.8017\n",
      "  Batch 1460/1778 - Loss: 0.5391, Accuracy: 0.8018\n",
      "  Batch 1470/1778 - Loss: 0.5384, Accuracy: 0.8021\n",
      "  Batch 1480/1778 - Loss: 0.5383, Accuracy: 0.8022\n",
      "  Batch 1490/1778 - Loss: 0.5380, Accuracy: 0.8023\n",
      "  Batch 1500/1778 - Loss: 0.5379, Accuracy: 0.8023\n",
      "  Batch 1510/1778 - Loss: 0.5376, Accuracy: 0.8023\n",
      "  Batch 1520/1778 - Loss: 0.5373, Accuracy: 0.8022\n",
      "  Batch 1530/1778 - Loss: 0.5366, Accuracy: 0.8026\n",
      "  Batch 1540/1778 - Loss: 0.5365, Accuracy: 0.8026\n",
      "  Batch 1550/1778 - Loss: 0.5358, Accuracy: 0.8028\n",
      "  Batch 1560/1778 - Loss: 0.5356, Accuracy: 0.8030\n",
      "  Batch 1570/1778 - Loss: 0.5347, Accuracy: 0.8033\n",
      "  Batch 1580/1778 - Loss: 0.5348, Accuracy: 0.8033\n",
      "  Batch 1590/1778 - Loss: 0.5340, Accuracy: 0.8036\n",
      "  Batch 1600/1778 - Loss: 0.5339, Accuracy: 0.8036\n",
      "  Batch 1610/1778 - Loss: 0.5339, Accuracy: 0.8035\n",
      "  Batch 1620/1778 - Loss: 0.5333, Accuracy: 0.8037\n",
      "  Batch 1630/1778 - Loss: 0.5329, Accuracy: 0.8038\n",
      "  Batch 1640/1778 - Loss: 0.5321, Accuracy: 0.8042\n",
      "  Batch 1650/1778 - Loss: 0.5325, Accuracy: 0.8041\n",
      "  Batch 1660/1778 - Loss: 0.5317, Accuracy: 0.8043\n",
      "  Batch 1670/1778 - Loss: 0.5311, Accuracy: 0.8046\n",
      "  Batch 1680/1778 - Loss: 0.5306, Accuracy: 0.8048\n",
      "  Batch 1690/1778 - Loss: 0.5301, Accuracy: 0.8049\n",
      "  Batch 1700/1778 - Loss: 0.5296, Accuracy: 0.8052\n",
      "  Batch 1710/1778 - Loss: 0.5293, Accuracy: 0.8054\n",
      "  Batch 1720/1778 - Loss: 0.5291, Accuracy: 0.8054\n",
      "  Batch 1730/1778 - Loss: 0.5288, Accuracy: 0.8055\n",
      "  Batch 1740/1778 - Loss: 0.5287, Accuracy: 0.8056\n",
      "  Batch 1750/1778 - Loss: 0.5277, Accuracy: 0.8060\n",
      "  Batch 1760/1778 - Loss: 0.5272, Accuracy: 0.8062\n",
      "  Batch 1770/1778 - Loss: 0.5268, Accuracy: 0.8062\n",
      "\n",
      "Kết quả Epoch 2:\n",
      "  Loss trung bình: 0.5263\n",
      "  Độ chính xác trung bình: 0.8064\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 3 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.5030, Accuracy: 0.8068\n",
      "  Batch 20/1778 - Loss: 0.4543, Accuracy: 0.8333\n",
      "  Batch 30/1778 - Loss: 0.4573, Accuracy: 0.8357\n",
      "  Batch 40/1778 - Loss: 0.4512, Accuracy: 0.8369\n",
      "  Batch 50/1778 - Loss: 0.4450, Accuracy: 0.8425\n",
      "  Batch 60/1778 - Loss: 0.4443, Accuracy: 0.8458\n",
      "  Batch 70/1778 - Loss: 0.4363, Accuracy: 0.8468\n",
      "  Batch 80/1778 - Loss: 0.4354, Accuracy: 0.8449\n",
      "  Batch 90/1778 - Loss: 0.4329, Accuracy: 0.8458\n",
      "  Batch 100/1778 - Loss: 0.4382, Accuracy: 0.8434\n",
      "  Batch 110/1778 - Loss: 0.4317, Accuracy: 0.8449\n",
      "  Batch 120/1778 - Loss: 0.4256, Accuracy: 0.8466\n",
      "  Batch 130/1778 - Loss: 0.4254, Accuracy: 0.8469\n",
      "  Batch 140/1778 - Loss: 0.4245, Accuracy: 0.8469\n",
      "  Batch 150/1778 - Loss: 0.4188, Accuracy: 0.8495\n",
      "  Batch 160/1778 - Loss: 0.4205, Accuracy: 0.8480\n",
      "  Batch 170/1778 - Loss: 0.4216, Accuracy: 0.8461\n",
      "  Batch 180/1778 - Loss: 0.4229, Accuracy: 0.8465\n",
      "  Batch 190/1778 - Loss: 0.4244, Accuracy: 0.8455\n",
      "  Batch 200/1778 - Loss: 0.4230, Accuracy: 0.8456\n",
      "  Batch 210/1778 - Loss: 0.4209, Accuracy: 0.8472\n",
      "  Batch 220/1778 - Loss: 0.4212, Accuracy: 0.8473\n",
      "  Batch 230/1778 - Loss: 0.4235, Accuracy: 0.8474\n",
      "  Batch 240/1778 - Loss: 0.4245, Accuracy: 0.8471\n",
      "  Batch 250/1778 - Loss: 0.4266, Accuracy: 0.8456\n",
      "  Batch 260/1778 - Loss: 0.4280, Accuracy: 0.8443\n",
      "  Batch 270/1778 - Loss: 0.4290, Accuracy: 0.8440\n",
      "  Batch 280/1778 - Loss: 0.4294, Accuracy: 0.8436\n",
      "  Batch 290/1778 - Loss: 0.4273, Accuracy: 0.8445\n",
      "  Batch 300/1778 - Loss: 0.4284, Accuracy: 0.8430\n",
      "  Batch 310/1778 - Loss: 0.4318, Accuracy: 0.8415\n",
      "  Batch 320/1778 - Loss: 0.4309, Accuracy: 0.8420\n",
      "  Batch 330/1778 - Loss: 0.4303, Accuracy: 0.8423\n",
      "  Batch 340/1778 - Loss: 0.4290, Accuracy: 0.8433\n",
      "  Batch 350/1778 - Loss: 0.4306, Accuracy: 0.8421\n",
      "  Batch 360/1778 - Loss: 0.4305, Accuracy: 0.8425\n",
      "  Batch 370/1778 - Loss: 0.4310, Accuracy: 0.8422\n",
      "  Batch 380/1778 - Loss: 0.4287, Accuracy: 0.8433\n",
      "  Batch 390/1778 - Loss: 0.4287, Accuracy: 0.8437\n",
      "  Batch 400/1778 - Loss: 0.4284, Accuracy: 0.8435\n",
      "  Batch 410/1778 - Loss: 0.4275, Accuracy: 0.8440\n",
      "  Batch 420/1778 - Loss: 0.4265, Accuracy: 0.8438\n",
      "  Batch 430/1778 - Loss: 0.4288, Accuracy: 0.8430\n",
      "  Batch 440/1778 - Loss: 0.4281, Accuracy: 0.8430\n",
      "  Batch 450/1778 - Loss: 0.4294, Accuracy: 0.8431\n",
      "  Batch 460/1778 - Loss: 0.4292, Accuracy: 0.8433\n",
      "  Batch 470/1778 - Loss: 0.4299, Accuracy: 0.8432\n",
      "  Batch 480/1778 - Loss: 0.4291, Accuracy: 0.8434\n",
      "  Batch 490/1778 - Loss: 0.4296, Accuracy: 0.8429\n",
      "  Batch 500/1778 - Loss: 0.4302, Accuracy: 0.8428\n",
      "  Batch 510/1778 - Loss: 0.4305, Accuracy: 0.8429\n",
      "  Batch 520/1778 - Loss: 0.4304, Accuracy: 0.8432\n",
      "  Batch 530/1778 - Loss: 0.4316, Accuracy: 0.8432\n",
      "  Batch 540/1778 - Loss: 0.4315, Accuracy: 0.8432\n",
      "  Batch 550/1778 - Loss: 0.4310, Accuracy: 0.8431\n",
      "  Batch 560/1778 - Loss: 0.4292, Accuracy: 0.8440\n",
      "  Batch 570/1778 - Loss: 0.4304, Accuracy: 0.8435\n",
      "  Batch 580/1778 - Loss: 0.4311, Accuracy: 0.8431\n",
      "  Batch 590/1778 - Loss: 0.4313, Accuracy: 0.8427\n",
      "  Batch 600/1778 - Loss: 0.4315, Accuracy: 0.8423\n",
      "  Batch 610/1778 - Loss: 0.4329, Accuracy: 0.8419\n",
      "  Batch 620/1778 - Loss: 0.4340, Accuracy: 0.8415\n",
      "  Batch 630/1778 - Loss: 0.4333, Accuracy: 0.8417\n",
      "  Batch 640/1778 - Loss: 0.4327, Accuracy: 0.8418\n",
      "  Batch 650/1778 - Loss: 0.4325, Accuracy: 0.8419\n",
      "  Batch 660/1778 - Loss: 0.4331, Accuracy: 0.8419\n",
      "  Batch 670/1778 - Loss: 0.4338, Accuracy: 0.8420\n",
      "  Batch 680/1778 - Loss: 0.4339, Accuracy: 0.8417\n",
      "  Batch 690/1778 - Loss: 0.4344, Accuracy: 0.8418\n",
      "  Batch 700/1778 - Loss: 0.4341, Accuracy: 0.8424\n",
      "  Batch 710/1778 - Loss: 0.4331, Accuracy: 0.8427\n",
      "  Batch 720/1778 - Loss: 0.4345, Accuracy: 0.8421\n",
      "  Batch 730/1778 - Loss: 0.4352, Accuracy: 0.8414\n",
      "  Batch 740/1778 - Loss: 0.4346, Accuracy: 0.8420\n",
      "  Batch 750/1778 - Loss: 0.4342, Accuracy: 0.8421\n",
      "  Batch 760/1778 - Loss: 0.4342, Accuracy: 0.8417\n",
      "  Batch 770/1778 - Loss: 0.4342, Accuracy: 0.8415\n",
      "  Batch 780/1778 - Loss: 0.4338, Accuracy: 0.8415\n",
      "  Batch 790/1778 - Loss: 0.4331, Accuracy: 0.8417\n",
      "  Batch 800/1778 - Loss: 0.4328, Accuracy: 0.8418\n",
      "  Batch 810/1778 - Loss: 0.4325, Accuracy: 0.8419\n",
      "  Batch 820/1778 - Loss: 0.4327, Accuracy: 0.8417\n",
      "  Batch 830/1778 - Loss: 0.4333, Accuracy: 0.8414\n",
      "  Batch 840/1778 - Loss: 0.4334, Accuracy: 0.8413\n",
      "  Batch 850/1778 - Loss: 0.4339, Accuracy: 0.8411\n",
      "  Batch 860/1778 - Loss: 0.4329, Accuracy: 0.8412\n",
      "  Batch 870/1778 - Loss: 0.4325, Accuracy: 0.8413\n",
      "  Batch 880/1778 - Loss: 0.4320, Accuracy: 0.8416\n",
      "  Batch 890/1778 - Loss: 0.4321, Accuracy: 0.8414\n",
      "  Batch 900/1778 - Loss: 0.4317, Accuracy: 0.8414\n",
      "  Batch 910/1778 - Loss: 0.4315, Accuracy: 0.8412\n",
      "  Batch 920/1778 - Loss: 0.4307, Accuracy: 0.8415\n",
      "  Batch 930/1778 - Loss: 0.4304, Accuracy: 0.8415\n",
      "  Batch 940/1778 - Loss: 0.4297, Accuracy: 0.8414\n",
      "  Batch 950/1778 - Loss: 0.4296, Accuracy: 0.8413\n",
      "  Batch 960/1778 - Loss: 0.4293, Accuracy: 0.8414\n",
      "  Batch 970/1778 - Loss: 0.4291, Accuracy: 0.8415\n",
      "  Batch 980/1778 - Loss: 0.4282, Accuracy: 0.8418\n",
      "  Batch 990/1778 - Loss: 0.4278, Accuracy: 0.8420\n",
      "  Batch 1000/1778 - Loss: 0.4277, Accuracy: 0.8421\n",
      "  Batch 1010/1778 - Loss: 0.4280, Accuracy: 0.8420\n",
      "  Batch 1020/1778 - Loss: 0.4279, Accuracy: 0.8420\n",
      "  Batch 1030/1778 - Loss: 0.4283, Accuracy: 0.8419\n",
      "  Batch 1040/1778 - Loss: 0.4279, Accuracy: 0.8420\n",
      "  Batch 1050/1778 - Loss: 0.4275, Accuracy: 0.8421\n",
      "  Batch 1060/1778 - Loss: 0.4272, Accuracy: 0.8422\n",
      "  Batch 1070/1778 - Loss: 0.4271, Accuracy: 0.8422\n",
      "  Batch 1080/1778 - Loss: 0.4273, Accuracy: 0.8421\n",
      "  Batch 1090/1778 - Loss: 0.4274, Accuracy: 0.8421\n",
      "  Batch 1100/1778 - Loss: 0.4279, Accuracy: 0.8420\n",
      "  Batch 1110/1778 - Loss: 0.4272, Accuracy: 0.8423\n",
      "  Batch 1120/1778 - Loss: 0.4275, Accuracy: 0.8422\n",
      "  Batch 1130/1778 - Loss: 0.4272, Accuracy: 0.8422\n",
      "  Batch 1140/1778 - Loss: 0.4265, Accuracy: 0.8425\n",
      "  Batch 1150/1778 - Loss: 0.4256, Accuracy: 0.8428\n",
      "  Batch 1160/1778 - Loss: 0.4259, Accuracy: 0.8427\n",
      "  Batch 1170/1778 - Loss: 0.4261, Accuracy: 0.8425\n",
      "  Batch 1180/1778 - Loss: 0.4268, Accuracy: 0.8420\n",
      "  Batch 1190/1778 - Loss: 0.4272, Accuracy: 0.8417\n",
      "  Batch 1200/1778 - Loss: 0.4267, Accuracy: 0.8419\n",
      "  Batch 1210/1778 - Loss: 0.4262, Accuracy: 0.8421\n",
      "  Batch 1220/1778 - Loss: 0.4264, Accuracy: 0.8421\n",
      "  Batch 1230/1778 - Loss: 0.4259, Accuracy: 0.8422\n",
      "  Batch 1240/1778 - Loss: 0.4260, Accuracy: 0.8422\n",
      "  Batch 1250/1778 - Loss: 0.4258, Accuracy: 0.8422\n",
      "  Batch 1260/1778 - Loss: 0.4254, Accuracy: 0.8423\n",
      "  Batch 1270/1778 - Loss: 0.4250, Accuracy: 0.8424\n",
      "  Batch 1280/1778 - Loss: 0.4251, Accuracy: 0.8423\n",
      "  Batch 1290/1778 - Loss: 0.4247, Accuracy: 0.8424\n",
      "  Batch 1300/1778 - Loss: 0.4238, Accuracy: 0.8426\n",
      "  Batch 1310/1778 - Loss: 0.4235, Accuracy: 0.8427\n",
      "  Batch 1320/1778 - Loss: 0.4236, Accuracy: 0.8426\n",
      "  Batch 1330/1778 - Loss: 0.4242, Accuracy: 0.8423\n",
      "  Batch 1340/1778 - Loss: 0.4243, Accuracy: 0.8422\n",
      "  Batch 1350/1778 - Loss: 0.4242, Accuracy: 0.8422\n",
      "  Batch 1360/1778 - Loss: 0.4245, Accuracy: 0.8422\n",
      "  Batch 1370/1778 - Loss: 0.4239, Accuracy: 0.8422\n",
      "  Batch 1380/1778 - Loss: 0.4245, Accuracy: 0.8420\n",
      "  Batch 1390/1778 - Loss: 0.4244, Accuracy: 0.8420\n",
      "  Batch 1400/1778 - Loss: 0.4243, Accuracy: 0.8422\n",
      "  Batch 1410/1778 - Loss: 0.4239, Accuracy: 0.8423\n",
      "  Batch 1420/1778 - Loss: 0.4235, Accuracy: 0.8425\n",
      "  Batch 1430/1778 - Loss: 0.4229, Accuracy: 0.8427\n",
      "  Batch 1440/1778 - Loss: 0.4228, Accuracy: 0.8428\n",
      "  Batch 1450/1778 - Loss: 0.4224, Accuracy: 0.8429\n",
      "  Batch 1460/1778 - Loss: 0.4227, Accuracy: 0.8429\n",
      "  Batch 1470/1778 - Loss: 0.4221, Accuracy: 0.8430\n",
      "  Batch 1480/1778 - Loss: 0.4220, Accuracy: 0.8429\n",
      "  Batch 1490/1778 - Loss: 0.4217, Accuracy: 0.8430\n",
      "  Batch 1500/1778 - Loss: 0.4220, Accuracy: 0.8428\n",
      "  Batch 1510/1778 - Loss: 0.4220, Accuracy: 0.8428\n",
      "  Batch 1520/1778 - Loss: 0.4214, Accuracy: 0.8431\n",
      "  Batch 1530/1778 - Loss: 0.4210, Accuracy: 0.8433\n",
      "  Batch 1540/1778 - Loss: 0.4213, Accuracy: 0.8432\n",
      "  Batch 1550/1778 - Loss: 0.4211, Accuracy: 0.8433\n",
      "  Batch 1560/1778 - Loss: 0.4215, Accuracy: 0.8431\n",
      "  Batch 1570/1778 - Loss: 0.4213, Accuracy: 0.8431\n",
      "  Batch 1580/1778 - Loss: 0.4209, Accuracy: 0.8432\n",
      "  Batch 1590/1778 - Loss: 0.4205, Accuracy: 0.8433\n",
      "  Batch 1600/1778 - Loss: 0.4201, Accuracy: 0.8435\n",
      "  Batch 1610/1778 - Loss: 0.4203, Accuracy: 0.8435\n",
      "  Batch 1620/1778 - Loss: 0.4201, Accuracy: 0.8436\n",
      "  Batch 1630/1778 - Loss: 0.4204, Accuracy: 0.8434\n",
      "  Batch 1640/1778 - Loss: 0.4198, Accuracy: 0.8437\n",
      "  Batch 1650/1778 - Loss: 0.4197, Accuracy: 0.8437\n",
      "  Batch 1660/1778 - Loss: 0.4202, Accuracy: 0.8436\n",
      "  Batch 1670/1778 - Loss: 0.4204, Accuracy: 0.8436\n",
      "  Batch 1680/1778 - Loss: 0.4203, Accuracy: 0.8436\n",
      "  Batch 1690/1778 - Loss: 0.4203, Accuracy: 0.8436\n",
      "  Batch 1700/1778 - Loss: 0.4203, Accuracy: 0.8436\n",
      "  Batch 1710/1778 - Loss: 0.4205, Accuracy: 0.8435\n",
      "  Batch 1720/1778 - Loss: 0.4204, Accuracy: 0.8435\n",
      "  Batch 1730/1778 - Loss: 0.4206, Accuracy: 0.8434\n",
      "  Batch 1740/1778 - Loss: 0.4204, Accuracy: 0.8434\n",
      "  Batch 1750/1778 - Loss: 0.4200, Accuracy: 0.8436\n",
      "  Batch 1760/1778 - Loss: 0.4195, Accuracy: 0.8438\n",
      "  Batch 1770/1778 - Loss: 0.4195, Accuracy: 0.8438\n",
      "\n",
      "Kết quả Epoch 3:\n",
      "  Loss trung bình: 0.4193\n",
      "  Độ chính xác trung bình: 0.8439\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 4 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.3719, Accuracy: 0.8523\n",
      "  Batch 20/1778 - Loss: 0.3406, Accuracy: 0.8616\n",
      "  Batch 30/1778 - Loss: 0.3685, Accuracy: 0.8609\n",
      "  Batch 40/1778 - Loss: 0.3629, Accuracy: 0.8620\n",
      "  Batch 50/1778 - Loss: 0.3613, Accuracy: 0.8664\n",
      "  Batch 60/1778 - Loss: 0.3662, Accuracy: 0.8648\n",
      "  Batch 70/1778 - Loss: 0.3588, Accuracy: 0.8658\n",
      "  Batch 80/1778 - Loss: 0.3638, Accuracy: 0.8634\n",
      "  Batch 90/1778 - Loss: 0.3668, Accuracy: 0.8609\n",
      "  Batch 100/1778 - Loss: 0.3656, Accuracy: 0.8611\n",
      "  Batch 110/1778 - Loss: 0.3644, Accuracy: 0.8632\n",
      "  Batch 120/1778 - Loss: 0.3581, Accuracy: 0.8662\n",
      "  Batch 130/1778 - Loss: 0.3532, Accuracy: 0.8669\n",
      "  Batch 140/1778 - Loss: 0.3517, Accuracy: 0.8679\n",
      "  Batch 150/1778 - Loss: 0.3550, Accuracy: 0.8665\n",
      "  Batch 160/1778 - Loss: 0.3602, Accuracy: 0.8637\n",
      "  Batch 170/1778 - Loss: 0.3623, Accuracy: 0.8631\n",
      "  Batch 180/1778 - Loss: 0.3661, Accuracy: 0.8622\n",
      "  Batch 190/1778 - Loss: 0.3632, Accuracy: 0.8632\n",
      "  Batch 200/1778 - Loss: 0.3628, Accuracy: 0.8635\n",
      "  Batch 210/1778 - Loss: 0.3623, Accuracy: 0.8639\n",
      "  Batch 220/1778 - Loss: 0.3608, Accuracy: 0.8647\n",
      "  Batch 230/1778 - Loss: 0.3624, Accuracy: 0.8640\n",
      "  Batch 240/1778 - Loss: 0.3607, Accuracy: 0.8653\n",
      "  Batch 250/1778 - Loss: 0.3641, Accuracy: 0.8639\n",
      "  Batch 260/1778 - Loss: 0.3638, Accuracy: 0.8643\n",
      "  Batch 270/1778 - Loss: 0.3641, Accuracy: 0.8643\n",
      "  Batch 280/1778 - Loss: 0.3644, Accuracy: 0.8639\n",
      "  Batch 290/1778 - Loss: 0.3651, Accuracy: 0.8642\n",
      "  Batch 300/1778 - Loss: 0.3650, Accuracy: 0.8648\n",
      "  Batch 310/1778 - Loss: 0.3652, Accuracy: 0.8645\n",
      "  Batch 320/1778 - Loss: 0.3622, Accuracy: 0.8659\n",
      "  Batch 330/1778 - Loss: 0.3639, Accuracy: 0.8651\n",
      "  Batch 340/1778 - Loss: 0.3616, Accuracy: 0.8659\n",
      "  Batch 350/1778 - Loss: 0.3609, Accuracy: 0.8663\n",
      "  Batch 360/1778 - Loss: 0.3622, Accuracy: 0.8654\n",
      "  Batch 370/1778 - Loss: 0.3628, Accuracy: 0.8650\n",
      "  Batch 380/1778 - Loss: 0.3644, Accuracy: 0.8651\n",
      "  Batch 390/1778 - Loss: 0.3649, Accuracy: 0.8652\n",
      "  Batch 400/1778 - Loss: 0.3644, Accuracy: 0.8657\n",
      "  Batch 410/1778 - Loss: 0.3640, Accuracy: 0.8655\n",
      "  Batch 420/1778 - Loss: 0.3648, Accuracy: 0.8651\n",
      "  Batch 430/1778 - Loss: 0.3625, Accuracy: 0.8664\n",
      "  Batch 440/1778 - Loss: 0.3614, Accuracy: 0.8671\n",
      "  Batch 450/1778 - Loss: 0.3618, Accuracy: 0.8670\n",
      "  Batch 460/1778 - Loss: 0.3614, Accuracy: 0.8672\n",
      "  Batch 470/1778 - Loss: 0.3623, Accuracy: 0.8669\n",
      "  Batch 480/1778 - Loss: 0.3630, Accuracy: 0.8667\n",
      "  Batch 490/1778 - Loss: 0.3624, Accuracy: 0.8670\n",
      "  Batch 500/1778 - Loss: 0.3622, Accuracy: 0.8670\n",
      "  Batch 510/1778 - Loss: 0.3622, Accuracy: 0.8667\n",
      "  Batch 520/1778 - Loss: 0.3636, Accuracy: 0.8659\n",
      "  Batch 530/1778 - Loss: 0.3632, Accuracy: 0.8658\n",
      "  Batch 540/1778 - Loss: 0.3626, Accuracy: 0.8657\n",
      "  Batch 550/1778 - Loss: 0.3621, Accuracy: 0.8660\n",
      "  Batch 560/1778 - Loss: 0.3622, Accuracy: 0.8663\n",
      "  Batch 570/1778 - Loss: 0.3630, Accuracy: 0.8658\n",
      "  Batch 580/1778 - Loss: 0.3615, Accuracy: 0.8664\n",
      "  Batch 590/1778 - Loss: 0.3604, Accuracy: 0.8668\n",
      "  Batch 600/1778 - Loss: 0.3597, Accuracy: 0.8671\n",
      "  Batch 610/1778 - Loss: 0.3596, Accuracy: 0.8673\n",
      "  Batch 620/1778 - Loss: 0.3593, Accuracy: 0.8674\n",
      "  Batch 630/1778 - Loss: 0.3600, Accuracy: 0.8672\n",
      "  Batch 640/1778 - Loss: 0.3602, Accuracy: 0.8670\n",
      "  Batch 650/1778 - Loss: 0.3604, Accuracy: 0.8665\n",
      "  Batch 660/1778 - Loss: 0.3604, Accuracy: 0.8663\n",
      "  Batch 670/1778 - Loss: 0.3594, Accuracy: 0.8668\n",
      "  Batch 680/1778 - Loss: 0.3591, Accuracy: 0.8670\n",
      "  Batch 690/1778 - Loss: 0.3592, Accuracy: 0.8669\n",
      "  Batch 700/1778 - Loss: 0.3588, Accuracy: 0.8672\n",
      "  Batch 710/1778 - Loss: 0.3592, Accuracy: 0.8671\n",
      "  Batch 720/1778 - Loss: 0.3598, Accuracy: 0.8670\n",
      "  Batch 730/1778 - Loss: 0.3608, Accuracy: 0.8666\n",
      "  Batch 740/1778 - Loss: 0.3605, Accuracy: 0.8665\n",
      "  Batch 750/1778 - Loss: 0.3594, Accuracy: 0.8669\n",
      "  Batch 760/1778 - Loss: 0.3595, Accuracy: 0.8669\n",
      "  Batch 770/1778 - Loss: 0.3591, Accuracy: 0.8670\n",
      "  Batch 780/1778 - Loss: 0.3583, Accuracy: 0.8674\n",
      "  Batch 790/1778 - Loss: 0.3580, Accuracy: 0.8674\n",
      "  Batch 800/1778 - Loss: 0.3580, Accuracy: 0.8674\n",
      "  Batch 810/1778 - Loss: 0.3578, Accuracy: 0.8676\n",
      "  Batch 820/1778 - Loss: 0.3581, Accuracy: 0.8677\n",
      "  Batch 830/1778 - Loss: 0.3571, Accuracy: 0.8680\n",
      "  Batch 840/1778 - Loss: 0.3564, Accuracy: 0.8683\n",
      "  Batch 850/1778 - Loss: 0.3574, Accuracy: 0.8680\n",
      "  Batch 860/1778 - Loss: 0.3562, Accuracy: 0.8685\n",
      "  Batch 870/1778 - Loss: 0.3558, Accuracy: 0.8686\n",
      "  Batch 880/1778 - Loss: 0.3563, Accuracy: 0.8686\n",
      "  Batch 890/1778 - Loss: 0.3562, Accuracy: 0.8685\n",
      "  Batch 900/1778 - Loss: 0.3561, Accuracy: 0.8685\n",
      "  Batch 910/1778 - Loss: 0.3564, Accuracy: 0.8684\n",
      "  Batch 920/1778 - Loss: 0.3558, Accuracy: 0.8685\n",
      "  Batch 930/1778 - Loss: 0.3553, Accuracy: 0.8684\n",
      "  Batch 940/1778 - Loss: 0.3557, Accuracy: 0.8684\n",
      "  Batch 950/1778 - Loss: 0.3566, Accuracy: 0.8682\n",
      "  Batch 960/1778 - Loss: 0.3563, Accuracy: 0.8683\n",
      "  Batch 970/1778 - Loss: 0.3563, Accuracy: 0.8682\n",
      "  Batch 980/1778 - Loss: 0.3569, Accuracy: 0.8680\n",
      "  Batch 990/1778 - Loss: 0.3567, Accuracy: 0.8681\n",
      "  Batch 1000/1778 - Loss: 0.3571, Accuracy: 0.8680\n",
      "  Batch 1010/1778 - Loss: 0.3575, Accuracy: 0.8678\n",
      "  Batch 1020/1778 - Loss: 0.3574, Accuracy: 0.8677\n",
      "  Batch 1030/1778 - Loss: 0.3577, Accuracy: 0.8674\n",
      "  Batch 1040/1778 - Loss: 0.3576, Accuracy: 0.8673\n",
      "  Batch 1050/1778 - Loss: 0.3576, Accuracy: 0.8672\n",
      "  Batch 1060/1778 - Loss: 0.3579, Accuracy: 0.8670\n",
      "  Batch 1070/1778 - Loss: 0.3586, Accuracy: 0.8668\n",
      "  Batch 1080/1778 - Loss: 0.3582, Accuracy: 0.8668\n",
      "  Batch 1090/1778 - Loss: 0.3581, Accuracy: 0.8671\n",
      "  Batch 1100/1778 - Loss: 0.3580, Accuracy: 0.8671\n",
      "  Batch 1110/1778 - Loss: 0.3589, Accuracy: 0.8667\n",
      "  Batch 1120/1778 - Loss: 0.3585, Accuracy: 0.8667\n",
      "  Batch 1130/1778 - Loss: 0.3584, Accuracy: 0.8668\n",
      "  Batch 1140/1778 - Loss: 0.3584, Accuracy: 0.8666\n",
      "  Batch 1150/1778 - Loss: 0.3583, Accuracy: 0.8666\n",
      "  Batch 1160/1778 - Loss: 0.3586, Accuracy: 0.8665\n",
      "  Batch 1170/1778 - Loss: 0.3585, Accuracy: 0.8668\n",
      "  Batch 1180/1778 - Loss: 0.3587, Accuracy: 0.8666\n",
      "  Batch 1190/1778 - Loss: 0.3583, Accuracy: 0.8668\n",
      "  Batch 1200/1778 - Loss: 0.3583, Accuracy: 0.8668\n",
      "  Batch 1210/1778 - Loss: 0.3582, Accuracy: 0.8667\n",
      "  Batch 1220/1778 - Loss: 0.3580, Accuracy: 0.8667\n",
      "  Batch 1230/1778 - Loss: 0.3577, Accuracy: 0.8668\n",
      "  Batch 1240/1778 - Loss: 0.3577, Accuracy: 0.8667\n",
      "  Batch 1250/1778 - Loss: 0.3575, Accuracy: 0.8667\n",
      "  Batch 1260/1778 - Loss: 0.3581, Accuracy: 0.8665\n",
      "  Batch 1270/1778 - Loss: 0.3575, Accuracy: 0.8665\n",
      "  Batch 1280/1778 - Loss: 0.3576, Accuracy: 0.8665\n",
      "  Batch 1290/1778 - Loss: 0.3578, Accuracy: 0.8664\n",
      "  Batch 1300/1778 - Loss: 0.3576, Accuracy: 0.8664\n",
      "  Batch 1310/1778 - Loss: 0.3573, Accuracy: 0.8666\n",
      "  Batch 1320/1778 - Loss: 0.3571, Accuracy: 0.8666\n",
      "  Batch 1330/1778 - Loss: 0.3572, Accuracy: 0.8666\n",
      "  Batch 1340/1778 - Loss: 0.3566, Accuracy: 0.8669\n",
      "  Batch 1350/1778 - Loss: 0.3565, Accuracy: 0.8670\n",
      "  Batch 1360/1778 - Loss: 0.3567, Accuracy: 0.8668\n",
      "  Batch 1370/1778 - Loss: 0.3566, Accuracy: 0.8667\n",
      "  Batch 1380/1778 - Loss: 0.3564, Accuracy: 0.8668\n",
      "  Batch 1390/1778 - Loss: 0.3562, Accuracy: 0.8668\n",
      "  Batch 1400/1778 - Loss: 0.3558, Accuracy: 0.8669\n",
      "  Batch 1410/1778 - Loss: 0.3556, Accuracy: 0.8671\n",
      "  Batch 1420/1778 - Loss: 0.3551, Accuracy: 0.8673\n",
      "  Batch 1430/1778 - Loss: 0.3548, Accuracy: 0.8673\n",
      "  Batch 1440/1778 - Loss: 0.3552, Accuracy: 0.8673\n",
      "  Batch 1450/1778 - Loss: 0.3554, Accuracy: 0.8671\n",
      "  Batch 1460/1778 - Loss: 0.3554, Accuracy: 0.8671\n",
      "  Batch 1470/1778 - Loss: 0.3555, Accuracy: 0.8671\n",
      "  Batch 1480/1778 - Loss: 0.3555, Accuracy: 0.8671\n",
      "  Batch 1490/1778 - Loss: 0.3552, Accuracy: 0.8673\n",
      "  Batch 1500/1778 - Loss: 0.3548, Accuracy: 0.8675\n",
      "  Batch 1510/1778 - Loss: 0.3548, Accuracy: 0.8675\n",
      "  Batch 1520/1778 - Loss: 0.3547, Accuracy: 0.8676\n",
      "  Batch 1530/1778 - Loss: 0.3543, Accuracy: 0.8677\n",
      "  Batch 1540/1778 - Loss: 0.3542, Accuracy: 0.8678\n",
      "  Batch 1550/1778 - Loss: 0.3545, Accuracy: 0.8676\n",
      "  Batch 1560/1778 - Loss: 0.3542, Accuracy: 0.8678\n",
      "  Batch 1570/1778 - Loss: 0.3542, Accuracy: 0.8677\n",
      "  Batch 1580/1778 - Loss: 0.3541, Accuracy: 0.8678\n",
      "  Batch 1590/1778 - Loss: 0.3544, Accuracy: 0.8678\n",
      "  Batch 1600/1778 - Loss: 0.3547, Accuracy: 0.8677\n",
      "  Batch 1610/1778 - Loss: 0.3543, Accuracy: 0.8678\n",
      "  Batch 1620/1778 - Loss: 0.3542, Accuracy: 0.8679\n",
      "  Batch 1630/1778 - Loss: 0.3540, Accuracy: 0.8679\n",
      "  Batch 1640/1778 - Loss: 0.3538, Accuracy: 0.8679\n",
      "  Batch 1650/1778 - Loss: 0.3538, Accuracy: 0.8680\n",
      "  Batch 1660/1778 - Loss: 0.3538, Accuracy: 0.8678\n",
      "  Batch 1670/1778 - Loss: 0.3538, Accuracy: 0.8679\n",
      "  Batch 1680/1778 - Loss: 0.3537, Accuracy: 0.8679\n",
      "  Batch 1690/1778 - Loss: 0.3539, Accuracy: 0.8678\n",
      "  Batch 1700/1778 - Loss: 0.3538, Accuracy: 0.8679\n",
      "  Batch 1710/1778 - Loss: 0.3534, Accuracy: 0.8680\n",
      "  Batch 1720/1778 - Loss: 0.3538, Accuracy: 0.8678\n",
      "  Batch 1730/1778 - Loss: 0.3536, Accuracy: 0.8678\n",
      "  Batch 1740/1778 - Loss: 0.3535, Accuracy: 0.8679\n",
      "  Batch 1750/1778 - Loss: 0.3531, Accuracy: 0.8680\n",
      "  Batch 1760/1778 - Loss: 0.3528, Accuracy: 0.8681\n",
      "  Batch 1770/1778 - Loss: 0.3525, Accuracy: 0.8683\n",
      "\n",
      "Kết quả Epoch 4:\n",
      "  Loss trung bình: 0.3525\n",
      "  Độ chính xác trung bình: 0.8683\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 5 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.2921, Accuracy: 0.8920\n",
      "  Batch 20/1778 - Loss: 0.2868, Accuracy: 0.8943\n",
      "  Batch 30/1778 - Loss: 0.3067, Accuracy: 0.8881\n",
      "  Batch 40/1778 - Loss: 0.3117, Accuracy: 0.8857\n",
      "  Batch 50/1778 - Loss: 0.3053, Accuracy: 0.8879\n",
      "  Batch 60/1778 - Loss: 0.3183, Accuracy: 0.8847\n",
      "  Batch 70/1778 - Loss: 0.3201, Accuracy: 0.8847\n",
      "  Batch 80/1778 - Loss: 0.3131, Accuracy: 0.8866\n",
      "  Batch 90/1778 - Loss: 0.3088, Accuracy: 0.8870\n",
      "  Batch 100/1778 - Loss: 0.3130, Accuracy: 0.8843\n",
      "  Batch 110/1778 - Loss: 0.3103, Accuracy: 0.8854\n",
      "  Batch 120/1778 - Loss: 0.3089, Accuracy: 0.8848\n",
      "  Batch 130/1778 - Loss: 0.3090, Accuracy: 0.8843\n",
      "  Batch 140/1778 - Loss: 0.3066, Accuracy: 0.8845\n",
      "  Batch 150/1778 - Loss: 0.3039, Accuracy: 0.8853\n",
      "  Batch 160/1778 - Loss: 0.3010, Accuracy: 0.8870\n",
      "  Batch 170/1778 - Loss: 0.3003, Accuracy: 0.8858\n",
      "  Batch 180/1778 - Loss: 0.2985, Accuracy: 0.8874\n",
      "  Batch 190/1778 - Loss: 0.2987, Accuracy: 0.8871\n",
      "  Batch 200/1778 - Loss: 0.2999, Accuracy: 0.8859\n",
      "  Batch 210/1778 - Loss: 0.3001, Accuracy: 0.8851\n",
      "  Batch 220/1778 - Loss: 0.3014, Accuracy: 0.8848\n",
      "  Batch 230/1778 - Loss: 0.2993, Accuracy: 0.8853\n",
      "  Batch 240/1778 - Loss: 0.2964, Accuracy: 0.8865\n",
      "  Batch 250/1778 - Loss: 0.2962, Accuracy: 0.8870\n",
      "  Batch 260/1778 - Loss: 0.2952, Accuracy: 0.8877\n",
      "  Batch 270/1778 - Loss: 0.2959, Accuracy: 0.8873\n",
      "  Batch 280/1778 - Loss: 0.2973, Accuracy: 0.8872\n",
      "  Batch 290/1778 - Loss: 0.2985, Accuracy: 0.8868\n",
      "  Batch 300/1778 - Loss: 0.2997, Accuracy: 0.8862\n",
      "  Batch 310/1778 - Loss: 0.2990, Accuracy: 0.8867\n",
      "  Batch 320/1778 - Loss: 0.2974, Accuracy: 0.8873\n",
      "  Batch 330/1778 - Loss: 0.2978, Accuracy: 0.8863\n",
      "  Batch 340/1778 - Loss: 0.2964, Accuracy: 0.8870\n",
      "  Batch 350/1778 - Loss: 0.2958, Accuracy: 0.8872\n",
      "  Batch 360/1778 - Loss: 0.2966, Accuracy: 0.8871\n",
      "  Batch 370/1778 - Loss: 0.2963, Accuracy: 0.8874\n",
      "  Batch 380/1778 - Loss: 0.2965, Accuracy: 0.8873\n",
      "  Batch 390/1778 - Loss: 0.2975, Accuracy: 0.8871\n",
      "  Batch 400/1778 - Loss: 0.2984, Accuracy: 0.8868\n",
      "  Batch 410/1778 - Loss: 0.2983, Accuracy: 0.8868\n",
      "  Batch 420/1778 - Loss: 0.2990, Accuracy: 0.8862\n",
      "  Batch 430/1778 - Loss: 0.2989, Accuracy: 0.8862\n",
      "  Batch 440/1778 - Loss: 0.2991, Accuracy: 0.8864\n",
      "  Batch 450/1778 - Loss: 0.2988, Accuracy: 0.8868\n",
      "  Batch 460/1778 - Loss: 0.2983, Accuracy: 0.8871\n",
      "  Batch 470/1778 - Loss: 0.2985, Accuracy: 0.8871\n",
      "  Batch 480/1778 - Loss: 0.2989, Accuracy: 0.8868\n",
      "  Batch 490/1778 - Loss: 0.2989, Accuracy: 0.8866\n",
      "  Batch 500/1778 - Loss: 0.2989, Accuracy: 0.8867\n",
      "  Batch 510/1778 - Loss: 0.2993, Accuracy: 0.8867\n",
      "  Batch 520/1778 - Loss: 0.3000, Accuracy: 0.8863\n",
      "  Batch 530/1778 - Loss: 0.3005, Accuracy: 0.8860\n",
      "  Batch 540/1778 - Loss: 0.3024, Accuracy: 0.8857\n",
      "  Batch 550/1778 - Loss: 0.3023, Accuracy: 0.8860\n",
      "  Batch 560/1778 - Loss: 0.3025, Accuracy: 0.8861\n",
      "  Batch 570/1778 - Loss: 0.3019, Accuracy: 0.8864\n",
      "  Batch 580/1778 - Loss: 0.3037, Accuracy: 0.8859\n",
      "  Batch 590/1778 - Loss: 0.3053, Accuracy: 0.8852\n",
      "  Batch 600/1778 - Loss: 0.3054, Accuracy: 0.8855\n",
      "  Batch 610/1778 - Loss: 0.3066, Accuracy: 0.8852\n",
      "  Batch 620/1778 - Loss: 0.3077, Accuracy: 0.8845\n",
      "  Batch 630/1778 - Loss: 0.3089, Accuracy: 0.8845\n",
      "  Batch 640/1778 - Loss: 0.3083, Accuracy: 0.8847\n",
      "  Batch 650/1778 - Loss: 0.3082, Accuracy: 0.8845\n",
      "  Batch 660/1778 - Loss: 0.3084, Accuracy: 0.8844\n",
      "  Batch 670/1778 - Loss: 0.3082, Accuracy: 0.8841\n",
      "  Batch 680/1778 - Loss: 0.3080, Accuracy: 0.8840\n",
      "  Batch 690/1778 - Loss: 0.3087, Accuracy: 0.8839\n",
      "  Batch 700/1778 - Loss: 0.3091, Accuracy: 0.8836\n",
      "  Batch 710/1778 - Loss: 0.3092, Accuracy: 0.8835\n",
      "  Batch 720/1778 - Loss: 0.3098, Accuracy: 0.8832\n",
      "  Batch 730/1778 - Loss: 0.3111, Accuracy: 0.8829\n",
      "  Batch 740/1778 - Loss: 0.3106, Accuracy: 0.8829\n",
      "  Batch 750/1778 - Loss: 0.3111, Accuracy: 0.8825\n",
      "  Batch 760/1778 - Loss: 0.3106, Accuracy: 0.8827\n",
      "  Batch 770/1778 - Loss: 0.3100, Accuracy: 0.8829\n",
      "  Batch 780/1778 - Loss: 0.3100, Accuracy: 0.8828\n",
      "  Batch 790/1778 - Loss: 0.3101, Accuracy: 0.8827\n",
      "  Batch 800/1778 - Loss: 0.3095, Accuracy: 0.8831\n",
      "  Batch 810/1778 - Loss: 0.3101, Accuracy: 0.8830\n",
      "  Batch 820/1778 - Loss: 0.3104, Accuracy: 0.8829\n",
      "  Batch 830/1778 - Loss: 0.3097, Accuracy: 0.8834\n",
      "  Batch 840/1778 - Loss: 0.3096, Accuracy: 0.8834\n",
      "  Batch 850/1778 - Loss: 0.3097, Accuracy: 0.8834\n",
      "  Batch 860/1778 - Loss: 0.3099, Accuracy: 0.8833\n",
      "  Batch 870/1778 - Loss: 0.3096, Accuracy: 0.8836\n",
      "  Batch 880/1778 - Loss: 0.3095, Accuracy: 0.8837\n",
      "  Batch 890/1778 - Loss: 0.3094, Accuracy: 0.8839\n",
      "  Batch 900/1778 - Loss: 0.3096, Accuracy: 0.8840\n",
      "  Batch 910/1778 - Loss: 0.3101, Accuracy: 0.8839\n",
      "  Batch 920/1778 - Loss: 0.3103, Accuracy: 0.8840\n",
      "  Batch 930/1778 - Loss: 0.3097, Accuracy: 0.8843\n",
      "  Batch 940/1778 - Loss: 0.3099, Accuracy: 0.8842\n",
      "  Batch 950/1778 - Loss: 0.3100, Accuracy: 0.8842\n",
      "  Batch 960/1778 - Loss: 0.3099, Accuracy: 0.8842\n",
      "  Batch 970/1778 - Loss: 0.3102, Accuracy: 0.8840\n",
      "  Batch 980/1778 - Loss: 0.3103, Accuracy: 0.8839\n",
      "  Batch 990/1778 - Loss: 0.3099, Accuracy: 0.8839\n",
      "  Batch 1000/1778 - Loss: 0.3090, Accuracy: 0.8843\n",
      "  Batch 1010/1778 - Loss: 0.3091, Accuracy: 0.8842\n",
      "  Batch 1020/1778 - Loss: 0.3087, Accuracy: 0.8843\n",
      "  Batch 1030/1778 - Loss: 0.3089, Accuracy: 0.8841\n",
      "  Batch 1040/1778 - Loss: 0.3095, Accuracy: 0.8840\n",
      "  Batch 1050/1778 - Loss: 0.3090, Accuracy: 0.8841\n",
      "  Batch 1060/1778 - Loss: 0.3096, Accuracy: 0.8839\n",
      "  Batch 1070/1778 - Loss: 0.3104, Accuracy: 0.8837\n",
      "  Batch 1080/1778 - Loss: 0.3101, Accuracy: 0.8837\n",
      "  Batch 1090/1778 - Loss: 0.3099, Accuracy: 0.8838\n",
      "  Batch 1100/1778 - Loss: 0.3096, Accuracy: 0.8839\n",
      "  Batch 1110/1778 - Loss: 0.3092, Accuracy: 0.8841\n",
      "  Batch 1120/1778 - Loss: 0.3098, Accuracy: 0.8837\n",
      "  Batch 1130/1778 - Loss: 0.3097, Accuracy: 0.8836\n",
      "  Batch 1140/1778 - Loss: 0.3102, Accuracy: 0.8836\n",
      "  Batch 1150/1778 - Loss: 0.3100, Accuracy: 0.8837\n",
      "  Batch 1160/1778 - Loss: 0.3096, Accuracy: 0.8839\n",
      "  Batch 1170/1778 - Loss: 0.3097, Accuracy: 0.8839\n",
      "  Batch 1180/1778 - Loss: 0.3101, Accuracy: 0.8836\n",
      "  Batch 1190/1778 - Loss: 0.3106, Accuracy: 0.8835\n",
      "  Batch 1200/1778 - Loss: 0.3106, Accuracy: 0.8834\n",
      "  Batch 1210/1778 - Loss: 0.3107, Accuracy: 0.8834\n",
      "  Batch 1220/1778 - Loss: 0.3103, Accuracy: 0.8835\n",
      "  Batch 1230/1778 - Loss: 0.3102, Accuracy: 0.8836\n",
      "  Batch 1240/1778 - Loss: 0.3103, Accuracy: 0.8837\n",
      "  Batch 1250/1778 - Loss: 0.3107, Accuracy: 0.8835\n",
      "  Batch 1260/1778 - Loss: 0.3110, Accuracy: 0.8835\n",
      "  Batch 1270/1778 - Loss: 0.3107, Accuracy: 0.8836\n",
      "  Batch 1280/1778 - Loss: 0.3106, Accuracy: 0.8836\n",
      "  Batch 1290/1778 - Loss: 0.3105, Accuracy: 0.8837\n",
      "  Batch 1300/1778 - Loss: 0.3104, Accuracy: 0.8837\n",
      "  Batch 1310/1778 - Loss: 0.3104, Accuracy: 0.8836\n",
      "  Batch 1320/1778 - Loss: 0.3105, Accuracy: 0.8835\n",
      "  Batch 1330/1778 - Loss: 0.3104, Accuracy: 0.8836\n",
      "  Batch 1340/1778 - Loss: 0.3100, Accuracy: 0.8838\n",
      "  Batch 1350/1778 - Loss: 0.3100, Accuracy: 0.8839\n",
      "  Batch 1360/1778 - Loss: 0.3095, Accuracy: 0.8840\n",
      "  Batch 1370/1778 - Loss: 0.3090, Accuracy: 0.8842\n",
      "  Batch 1380/1778 - Loss: 0.3090, Accuracy: 0.8841\n",
      "  Batch 1390/1778 - Loss: 0.3089, Accuracy: 0.8841\n",
      "  Batch 1400/1778 - Loss: 0.3084, Accuracy: 0.8843\n",
      "  Batch 1410/1778 - Loss: 0.3084, Accuracy: 0.8843\n",
      "  Batch 1420/1778 - Loss: 0.3089, Accuracy: 0.8841\n",
      "  Batch 1430/1778 - Loss: 0.3089, Accuracy: 0.8842\n",
      "  Batch 1440/1778 - Loss: 0.3089, Accuracy: 0.8842\n",
      "  Batch 1450/1778 - Loss: 0.3089, Accuracy: 0.8841\n",
      "  Batch 1460/1778 - Loss: 0.3087, Accuracy: 0.8841\n",
      "  Batch 1470/1778 - Loss: 0.3083, Accuracy: 0.8841\n",
      "  Batch 1480/1778 - Loss: 0.3082, Accuracy: 0.8842\n",
      "  Batch 1490/1778 - Loss: 0.3084, Accuracy: 0.8842\n",
      "  Batch 1500/1778 - Loss: 0.3082, Accuracy: 0.8843\n",
      "  Batch 1510/1778 - Loss: 0.3082, Accuracy: 0.8844\n",
      "  Batch 1520/1778 - Loss: 0.3078, Accuracy: 0.8846\n",
      "  Batch 1530/1778 - Loss: 0.3079, Accuracy: 0.8846\n",
      "  Batch 1540/1778 - Loss: 0.3080, Accuracy: 0.8845\n",
      "  Batch 1550/1778 - Loss: 0.3078, Accuracy: 0.8846\n",
      "  Batch 1560/1778 - Loss: 0.3089, Accuracy: 0.8844\n",
      "  Batch 1570/1778 - Loss: 0.3089, Accuracy: 0.8844\n",
      "  Batch 1580/1778 - Loss: 0.3087, Accuracy: 0.8845\n",
      "  Batch 1590/1778 - Loss: 0.3087, Accuracy: 0.8846\n",
      "  Batch 1600/1778 - Loss: 0.3086, Accuracy: 0.8845\n",
      "  Batch 1610/1778 - Loss: 0.3084, Accuracy: 0.8846\n",
      "  Batch 1620/1778 - Loss: 0.3082, Accuracy: 0.8846\n",
      "  Batch 1630/1778 - Loss: 0.3081, Accuracy: 0.8847\n",
      "  Batch 1640/1778 - Loss: 0.3081, Accuracy: 0.8847\n",
      "  Batch 1650/1778 - Loss: 0.3081, Accuracy: 0.8847\n",
      "  Batch 1660/1778 - Loss: 0.3081, Accuracy: 0.8847\n",
      "  Batch 1670/1778 - Loss: 0.3077, Accuracy: 0.8848\n",
      "  Batch 1680/1778 - Loss: 0.3076, Accuracy: 0.8849\n",
      "  Batch 1690/1778 - Loss: 0.3073, Accuracy: 0.8849\n",
      "  Batch 1700/1778 - Loss: 0.3072, Accuracy: 0.8850\n",
      "  Batch 1710/1778 - Loss: 0.3071, Accuracy: 0.8851\n",
      "  Batch 1720/1778 - Loss: 0.3073, Accuracy: 0.8851\n",
      "  Batch 1730/1778 - Loss: 0.3073, Accuracy: 0.8851\n",
      "  Batch 1740/1778 - Loss: 0.3072, Accuracy: 0.8851\n",
      "  Batch 1750/1778 - Loss: 0.3074, Accuracy: 0.8850\n",
      "  Batch 1760/1778 - Loss: 0.3068, Accuracy: 0.8853\n",
      "  Batch 1770/1778 - Loss: 0.3066, Accuracy: 0.8853\n",
      "\n",
      "Kết quả Epoch 5:\n",
      "  Loss trung bình: 0.3067\n",
      "  Độ chính xác trung bình: 0.8853\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 6 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.2663, Accuracy: 0.8977\n",
      "  Batch 20/1778 - Loss: 0.2417, Accuracy: 0.9077\n",
      "  Batch 30/1778 - Loss: 0.2518, Accuracy: 0.9042\n",
      "  Batch 40/1778 - Loss: 0.2601, Accuracy: 0.9009\n",
      "  Batch 50/1778 - Loss: 0.2682, Accuracy: 0.8995\n",
      "  Batch 60/1778 - Loss: 0.2686, Accuracy: 0.8986\n",
      "  Batch 70/1778 - Loss: 0.2591, Accuracy: 0.9036\n",
      "  Batch 80/1778 - Loss: 0.2535, Accuracy: 0.9070\n",
      "  Batch 90/1778 - Loss: 0.2532, Accuracy: 0.9080\n",
      "  Batch 100/1778 - Loss: 0.2567, Accuracy: 0.9038\n",
      "  Batch 110/1778 - Loss: 0.2570, Accuracy: 0.9040\n",
      "  Batch 120/1778 - Loss: 0.2629, Accuracy: 0.9024\n",
      "  Batch 130/1778 - Loss: 0.2621, Accuracy: 0.9020\n",
      "  Batch 140/1778 - Loss: 0.2633, Accuracy: 0.9027\n",
      "  Batch 150/1778 - Loss: 0.2668, Accuracy: 0.9011\n",
      "  Batch 160/1778 - Loss: 0.2689, Accuracy: 0.9008\n",
      "  Batch 170/1778 - Loss: 0.2688, Accuracy: 0.9011\n",
      "  Batch 180/1778 - Loss: 0.2709, Accuracy: 0.9004\n",
      "  Batch 190/1778 - Loss: 0.2751, Accuracy: 0.8986\n",
      "  Batch 200/1778 - Loss: 0.2747, Accuracy: 0.8986\n",
      "  Batch 210/1778 - Loss: 0.2744, Accuracy: 0.8985\n",
      "  Batch 220/1778 - Loss: 0.2738, Accuracy: 0.8988\n",
      "  Batch 230/1778 - Loss: 0.2730, Accuracy: 0.8994\n",
      "  Batch 240/1778 - Loss: 0.2718, Accuracy: 0.8990\n",
      "  Batch 250/1778 - Loss: 0.2754, Accuracy: 0.8980\n",
      "  Batch 260/1778 - Loss: 0.2773, Accuracy: 0.8972\n",
      "  Batch 270/1778 - Loss: 0.2785, Accuracy: 0.8971\n",
      "  Batch 280/1778 - Loss: 0.2781, Accuracy: 0.8972\n",
      "  Batch 290/1778 - Loss: 0.2775, Accuracy: 0.8969\n",
      "  Batch 300/1778 - Loss: 0.2758, Accuracy: 0.8976\n",
      "  Batch 310/1778 - Loss: 0.2749, Accuracy: 0.8976\n",
      "  Batch 320/1778 - Loss: 0.2751, Accuracy: 0.8972\n",
      "  Batch 330/1778 - Loss: 0.2760, Accuracy: 0.8966\n",
      "  Batch 340/1778 - Loss: 0.2769, Accuracy: 0.8963\n",
      "  Batch 350/1778 - Loss: 0.2775, Accuracy: 0.8964\n",
      "  Batch 360/1778 - Loss: 0.2767, Accuracy: 0.8959\n",
      "  Batch 370/1778 - Loss: 0.2754, Accuracy: 0.8965\n",
      "  Batch 380/1778 - Loss: 0.2752, Accuracy: 0.8967\n",
      "  Batch 390/1778 - Loss: 0.2754, Accuracy: 0.8963\n",
      "  Batch 400/1778 - Loss: 0.2750, Accuracy: 0.8967\n",
      "  Batch 410/1778 - Loss: 0.2763, Accuracy: 0.8963\n",
      "  Batch 420/1778 - Loss: 0.2762, Accuracy: 0.8968\n",
      "  Batch 430/1778 - Loss: 0.2768, Accuracy: 0.8965\n",
      "  Batch 440/1778 - Loss: 0.2762, Accuracy: 0.8966\n",
      "  Batch 450/1778 - Loss: 0.2760, Accuracy: 0.8965\n",
      "  Batch 460/1778 - Loss: 0.2751, Accuracy: 0.8966\n",
      "  Batch 470/1778 - Loss: 0.2748, Accuracy: 0.8966\n",
      "  Batch 480/1778 - Loss: 0.2757, Accuracy: 0.8960\n",
      "  Batch 490/1778 - Loss: 0.2766, Accuracy: 0.8959\n",
      "  Batch 500/1778 - Loss: 0.2756, Accuracy: 0.8964\n",
      "  Batch 510/1778 - Loss: 0.2763, Accuracy: 0.8963\n",
      "  Batch 520/1778 - Loss: 0.2768, Accuracy: 0.8964\n",
      "  Batch 530/1778 - Loss: 0.2770, Accuracy: 0.8965\n",
      "  Batch 540/1778 - Loss: 0.2774, Accuracy: 0.8963\n",
      "  Batch 550/1778 - Loss: 0.2763, Accuracy: 0.8968\n",
      "  Batch 560/1778 - Loss: 0.2775, Accuracy: 0.8967\n",
      "  Batch 570/1778 - Loss: 0.2777, Accuracy: 0.8966\n",
      "  Batch 580/1778 - Loss: 0.2774, Accuracy: 0.8968\n",
      "  Batch 590/1778 - Loss: 0.2780, Accuracy: 0.8968\n",
      "  Batch 600/1778 - Loss: 0.2788, Accuracy: 0.8965\n",
      "  Batch 610/1778 - Loss: 0.2786, Accuracy: 0.8964\n",
      "  Batch 620/1778 - Loss: 0.2782, Accuracy: 0.8968\n",
      "  Batch 630/1778 - Loss: 0.2782, Accuracy: 0.8967\n",
      "  Batch 640/1778 - Loss: 0.2778, Accuracy: 0.8968\n",
      "  Batch 650/1778 - Loss: 0.2783, Accuracy: 0.8963\n",
      "  Batch 660/1778 - Loss: 0.2779, Accuracy: 0.8966\n",
      "  Batch 670/1778 - Loss: 0.2775, Accuracy: 0.8967\n",
      "  Batch 680/1778 - Loss: 0.2772, Accuracy: 0.8969\n",
      "  Batch 690/1778 - Loss: 0.2764, Accuracy: 0.8972\n",
      "  Batch 700/1778 - Loss: 0.2754, Accuracy: 0.8973\n",
      "  Batch 710/1778 - Loss: 0.2744, Accuracy: 0.8975\n",
      "  Batch 720/1778 - Loss: 0.2748, Accuracy: 0.8974\n",
      "  Batch 730/1778 - Loss: 0.2742, Accuracy: 0.8977\n",
      "  Batch 740/1778 - Loss: 0.2751, Accuracy: 0.8975\n",
      "  Batch 750/1778 - Loss: 0.2758, Accuracy: 0.8972\n",
      "  Batch 760/1778 - Loss: 0.2753, Accuracy: 0.8974\n",
      "  Batch 770/1778 - Loss: 0.2749, Accuracy: 0.8977\n",
      "  Batch 780/1778 - Loss: 0.2747, Accuracy: 0.8977\n",
      "  Batch 790/1778 - Loss: 0.2743, Accuracy: 0.8978\n",
      "  Batch 800/1778 - Loss: 0.2753, Accuracy: 0.8976\n",
      "  Batch 810/1778 - Loss: 0.2743, Accuracy: 0.8978\n",
      "  Batch 820/1778 - Loss: 0.2744, Accuracy: 0.8979\n",
      "  Batch 830/1778 - Loss: 0.2738, Accuracy: 0.8983\n",
      "  Batch 840/1778 - Loss: 0.2737, Accuracy: 0.8984\n",
      "  Batch 850/1778 - Loss: 0.2741, Accuracy: 0.8982\n",
      "  Batch 860/1778 - Loss: 0.2733, Accuracy: 0.8986\n",
      "  Batch 870/1778 - Loss: 0.2730, Accuracy: 0.8986\n",
      "  Batch 880/1778 - Loss: 0.2728, Accuracy: 0.8987\n",
      "  Batch 890/1778 - Loss: 0.2718, Accuracy: 0.8990\n",
      "  Batch 900/1778 - Loss: 0.2718, Accuracy: 0.8990\n",
      "  Batch 910/1778 - Loss: 0.2721, Accuracy: 0.8989\n",
      "  Batch 920/1778 - Loss: 0.2719, Accuracy: 0.8990\n",
      "  Batch 930/1778 - Loss: 0.2727, Accuracy: 0.8987\n",
      "  Batch 940/1778 - Loss: 0.2721, Accuracy: 0.8989\n",
      "  Batch 950/1778 - Loss: 0.2719, Accuracy: 0.8990\n",
      "  Batch 960/1778 - Loss: 0.2722, Accuracy: 0.8988\n",
      "  Batch 970/1778 - Loss: 0.2718, Accuracy: 0.8989\n",
      "  Batch 980/1778 - Loss: 0.2717, Accuracy: 0.8989\n",
      "  Batch 990/1778 - Loss: 0.2712, Accuracy: 0.8992\n",
      "  Batch 1000/1778 - Loss: 0.2711, Accuracy: 0.8993\n",
      "  Batch 1010/1778 - Loss: 0.2713, Accuracy: 0.8991\n",
      "  Batch 1020/1778 - Loss: 0.2710, Accuracy: 0.8993\n",
      "  Batch 1030/1778 - Loss: 0.2711, Accuracy: 0.8995\n",
      "  Batch 1040/1778 - Loss: 0.2707, Accuracy: 0.8995\n",
      "  Batch 1050/1778 - Loss: 0.2712, Accuracy: 0.8993\n",
      "  Batch 1060/1778 - Loss: 0.2707, Accuracy: 0.8995\n",
      "  Batch 1070/1778 - Loss: 0.2705, Accuracy: 0.8996\n",
      "  Batch 1080/1778 - Loss: 0.2698, Accuracy: 0.8997\n",
      "  Batch 1090/1778 - Loss: 0.2696, Accuracy: 0.8999\n",
      "  Batch 1100/1778 - Loss: 0.2699, Accuracy: 0.8999\n",
      "  Batch 1110/1778 - Loss: 0.2703, Accuracy: 0.8999\n",
      "  Batch 1120/1778 - Loss: 0.2703, Accuracy: 0.8998\n",
      "  Batch 1130/1778 - Loss: 0.2704, Accuracy: 0.8996\n",
      "  Batch 1140/1778 - Loss: 0.2711, Accuracy: 0.8993\n",
      "  Batch 1150/1778 - Loss: 0.2711, Accuracy: 0.8994\n",
      "  Batch 1160/1778 - Loss: 0.2713, Accuracy: 0.8994\n",
      "  Batch 1170/1778 - Loss: 0.2708, Accuracy: 0.8995\n",
      "  Batch 1180/1778 - Loss: 0.2710, Accuracy: 0.8994\n",
      "  Batch 1190/1778 - Loss: 0.2713, Accuracy: 0.8993\n",
      "  Batch 1200/1778 - Loss: 0.2712, Accuracy: 0.8993\n",
      "  Batch 1210/1778 - Loss: 0.2710, Accuracy: 0.8994\n",
      "  Batch 1220/1778 - Loss: 0.2716, Accuracy: 0.8991\n",
      "  Batch 1230/1778 - Loss: 0.2719, Accuracy: 0.8990\n",
      "  Batch 1240/1778 - Loss: 0.2718, Accuracy: 0.8990\n",
      "  Batch 1250/1778 - Loss: 0.2717, Accuracy: 0.8991\n",
      "  Batch 1260/1778 - Loss: 0.2716, Accuracy: 0.8991\n",
      "  Batch 1270/1778 - Loss: 0.2715, Accuracy: 0.8991\n",
      "  Batch 1280/1778 - Loss: 0.2711, Accuracy: 0.8992\n",
      "  Batch 1290/1778 - Loss: 0.2710, Accuracy: 0.8992\n",
      "  Batch 1300/1778 - Loss: 0.2706, Accuracy: 0.8993\n",
      "  Batch 1310/1778 - Loss: 0.2710, Accuracy: 0.8991\n",
      "  Batch 1320/1778 - Loss: 0.2712, Accuracy: 0.8990\n",
      "  Batch 1330/1778 - Loss: 0.2714, Accuracy: 0.8989\n",
      "  Batch 1340/1778 - Loss: 0.2715, Accuracy: 0.8988\n",
      "  Batch 1350/1778 - Loss: 0.2722, Accuracy: 0.8986\n",
      "  Batch 1360/1778 - Loss: 0.2724, Accuracy: 0.8985\n",
      "  Batch 1370/1778 - Loss: 0.2723, Accuracy: 0.8986\n",
      "  Batch 1380/1778 - Loss: 0.2723, Accuracy: 0.8985\n",
      "  Batch 1390/1778 - Loss: 0.2724, Accuracy: 0.8984\n",
      "  Batch 1400/1778 - Loss: 0.2721, Accuracy: 0.8984\n",
      "  Batch 1410/1778 - Loss: 0.2719, Accuracy: 0.8985\n",
      "  Batch 1420/1778 - Loss: 0.2722, Accuracy: 0.8985\n",
      "  Batch 1430/1778 - Loss: 0.2723, Accuracy: 0.8985\n",
      "  Batch 1440/1778 - Loss: 0.2721, Accuracy: 0.8986\n",
      "  Batch 1450/1778 - Loss: 0.2718, Accuracy: 0.8988\n",
      "  Batch 1460/1778 - Loss: 0.2719, Accuracy: 0.8987\n",
      "  Batch 1470/1778 - Loss: 0.2721, Accuracy: 0.8986\n",
      "  Batch 1480/1778 - Loss: 0.2719, Accuracy: 0.8987\n",
      "  Batch 1490/1778 - Loss: 0.2717, Accuracy: 0.8989\n",
      "  Batch 1500/1778 - Loss: 0.2711, Accuracy: 0.8990\n",
      "  Batch 1510/1778 - Loss: 0.2716, Accuracy: 0.8988\n",
      "  Batch 1520/1778 - Loss: 0.2713, Accuracy: 0.8989\n",
      "  Batch 1530/1778 - Loss: 0.2711, Accuracy: 0.8990\n",
      "  Batch 1540/1778 - Loss: 0.2711, Accuracy: 0.8990\n",
      "  Batch 1550/1778 - Loss: 0.2710, Accuracy: 0.8992\n",
      "  Batch 1560/1778 - Loss: 0.2717, Accuracy: 0.8989\n",
      "  Batch 1570/1778 - Loss: 0.2716, Accuracy: 0.8988\n",
      "  Batch 1580/1778 - Loss: 0.2718, Accuracy: 0.8987\n",
      "  Batch 1590/1778 - Loss: 0.2722, Accuracy: 0.8986\n",
      "  Batch 1600/1778 - Loss: 0.2721, Accuracy: 0.8986\n",
      "  Batch 1610/1778 - Loss: 0.2718, Accuracy: 0.8987\n",
      "  Batch 1620/1778 - Loss: 0.2724, Accuracy: 0.8985\n",
      "  Batch 1630/1778 - Loss: 0.2726, Accuracy: 0.8983\n",
      "  Batch 1640/1778 - Loss: 0.2726, Accuracy: 0.8983\n",
      "  Batch 1650/1778 - Loss: 0.2727, Accuracy: 0.8982\n",
      "  Batch 1660/1778 - Loss: 0.2727, Accuracy: 0.8982\n",
      "  Batch 1670/1778 - Loss: 0.2723, Accuracy: 0.8983\n",
      "  Batch 1680/1778 - Loss: 0.2721, Accuracy: 0.8983\n",
      "  Batch 1690/1778 - Loss: 0.2718, Accuracy: 0.8984\n",
      "  Batch 1700/1778 - Loss: 0.2717, Accuracy: 0.8984\n",
      "  Batch 1710/1778 - Loss: 0.2721, Accuracy: 0.8984\n",
      "  Batch 1720/1778 - Loss: 0.2716, Accuracy: 0.8987\n",
      "  Batch 1730/1778 - Loss: 0.2712, Accuracy: 0.8988\n",
      "  Batch 1740/1778 - Loss: 0.2714, Accuracy: 0.8987\n",
      "  Batch 1750/1778 - Loss: 0.2714, Accuracy: 0.8988\n",
      "  Batch 1760/1778 - Loss: 0.2715, Accuracy: 0.8987\n",
      "  Batch 1770/1778 - Loss: 0.2714, Accuracy: 0.8988\n",
      "\n",
      "Kết quả Epoch 6:\n",
      "  Loss trung bình: 0.2714\n",
      "  Độ chính xác trung bình: 0.8987\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 7 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.2007, Accuracy: 0.9119\n",
      "  Batch 20/1778 - Loss: 0.1964, Accuracy: 0.9226\n",
      "  Batch 30/1778 - Loss: 0.1853, Accuracy: 0.9294\n",
      "  Batch 40/1778 - Loss: 0.1974, Accuracy: 0.9284\n",
      "  Batch 50/1778 - Loss: 0.2154, Accuracy: 0.9185\n",
      "  Batch 60/1778 - Loss: 0.2235, Accuracy: 0.9170\n",
      "  Batch 70/1778 - Loss: 0.2305, Accuracy: 0.9133\n",
      "  Batch 80/1778 - Loss: 0.2332, Accuracy: 0.9128\n",
      "  Batch 90/1778 - Loss: 0.2313, Accuracy: 0.9128\n",
      "  Batch 100/1778 - Loss: 0.2307, Accuracy: 0.9115\n",
      "  Batch 110/1778 - Loss: 0.2325, Accuracy: 0.9102\n",
      "  Batch 120/1778 - Loss: 0.2358, Accuracy: 0.9104\n",
      "  Batch 130/1778 - Loss: 0.2373, Accuracy: 0.9101\n",
      "  Batch 140/1778 - Loss: 0.2386, Accuracy: 0.9091\n",
      "  Batch 150/1778 - Loss: 0.2402, Accuracy: 0.9083\n",
      "  Batch 160/1778 - Loss: 0.2384, Accuracy: 0.9101\n",
      "  Batch 170/1778 - Loss: 0.2361, Accuracy: 0.9112\n",
      "  Batch 180/1778 - Loss: 0.2355, Accuracy: 0.9116\n",
      "  Batch 190/1778 - Loss: 0.2353, Accuracy: 0.9115\n",
      "  Batch 200/1778 - Loss: 0.2374, Accuracy: 0.9118\n",
      "  Batch 210/1778 - Loss: 0.2385, Accuracy: 0.9117\n",
      "  Batch 220/1778 - Loss: 0.2370, Accuracy: 0.9119\n",
      "  Batch 230/1778 - Loss: 0.2361, Accuracy: 0.9123\n",
      "  Batch 240/1778 - Loss: 0.2380, Accuracy: 0.9113\n",
      "  Batch 250/1778 - Loss: 0.2386, Accuracy: 0.9115\n",
      "  Batch 260/1778 - Loss: 0.2378, Accuracy: 0.9118\n",
      "  Batch 270/1778 - Loss: 0.2377, Accuracy: 0.9128\n",
      "  Batch 280/1778 - Loss: 0.2354, Accuracy: 0.9130\n",
      "  Batch 290/1778 - Loss: 0.2347, Accuracy: 0.9132\n",
      "  Batch 300/1778 - Loss: 0.2361, Accuracy: 0.9128\n",
      "  Batch 310/1778 - Loss: 0.2366, Accuracy: 0.9128\n",
      "  Batch 320/1778 - Loss: 0.2361, Accuracy: 0.9131\n",
      "  Batch 330/1778 - Loss: 0.2361, Accuracy: 0.9130\n",
      "  Batch 340/1778 - Loss: 0.2356, Accuracy: 0.9131\n",
      "  Batch 350/1778 - Loss: 0.2361, Accuracy: 0.9129\n",
      "  Batch 360/1778 - Loss: 0.2351, Accuracy: 0.9133\n",
      "  Batch 370/1778 - Loss: 0.2347, Accuracy: 0.9133\n",
      "  Batch 380/1778 - Loss: 0.2360, Accuracy: 0.9129\n",
      "  Batch 390/1778 - Loss: 0.2372, Accuracy: 0.9120\n",
      "  Batch 400/1778 - Loss: 0.2375, Accuracy: 0.9120\n",
      "  Batch 410/1778 - Loss: 0.2359, Accuracy: 0.9124\n",
      "  Batch 420/1778 - Loss: 0.2368, Accuracy: 0.9121\n",
      "  Batch 430/1778 - Loss: 0.2368, Accuracy: 0.9118\n",
      "  Batch 440/1778 - Loss: 0.2369, Accuracy: 0.9122\n",
      "  Batch 450/1778 - Loss: 0.2383, Accuracy: 0.9117\n",
      "  Batch 460/1778 - Loss: 0.2387, Accuracy: 0.9111\n",
      "  Batch 470/1778 - Loss: 0.2395, Accuracy: 0.9106\n",
      "  Batch 480/1778 - Loss: 0.2405, Accuracy: 0.9104\n",
      "  Batch 490/1778 - Loss: 0.2398, Accuracy: 0.9108\n",
      "  Batch 500/1778 - Loss: 0.2405, Accuracy: 0.9104\n",
      "  Batch 510/1778 - Loss: 0.2411, Accuracy: 0.9103\n",
      "  Batch 520/1778 - Loss: 0.2427, Accuracy: 0.9098\n",
      "  Batch 530/1778 - Loss: 0.2423, Accuracy: 0.9100\n",
      "  Batch 540/1778 - Loss: 0.2417, Accuracy: 0.9100\n",
      "  Batch 550/1778 - Loss: 0.2421, Accuracy: 0.9098\n",
      "  Batch 560/1778 - Loss: 0.2427, Accuracy: 0.9093\n",
      "  Batch 570/1778 - Loss: 0.2423, Accuracy: 0.9095\n",
      "  Batch 580/1778 - Loss: 0.2426, Accuracy: 0.9093\n",
      "  Batch 590/1778 - Loss: 0.2425, Accuracy: 0.9092\n",
      "  Batch 600/1778 - Loss: 0.2430, Accuracy: 0.9088\n",
      "  Batch 610/1778 - Loss: 0.2433, Accuracy: 0.9084\n",
      "  Batch 620/1778 - Loss: 0.2442, Accuracy: 0.9081\n",
      "  Batch 630/1778 - Loss: 0.2446, Accuracy: 0.9080\n",
      "  Batch 640/1778 - Loss: 0.2448, Accuracy: 0.9077\n",
      "  Batch 650/1778 - Loss: 0.2444, Accuracy: 0.9077\n",
      "  Batch 660/1778 - Loss: 0.2432, Accuracy: 0.9081\n",
      "  Batch 670/1778 - Loss: 0.2432, Accuracy: 0.9080\n",
      "  Batch 680/1778 - Loss: 0.2427, Accuracy: 0.9081\n",
      "  Batch 690/1778 - Loss: 0.2431, Accuracy: 0.9081\n",
      "  Batch 700/1778 - Loss: 0.2435, Accuracy: 0.9079\n",
      "  Batch 710/1778 - Loss: 0.2436, Accuracy: 0.9079\n",
      "  Batch 720/1778 - Loss: 0.2439, Accuracy: 0.9076\n",
      "  Batch 730/1778 - Loss: 0.2440, Accuracy: 0.9074\n",
      "  Batch 740/1778 - Loss: 0.2435, Accuracy: 0.9076\n",
      "  Batch 750/1778 - Loss: 0.2439, Accuracy: 0.9074\n",
      "  Batch 760/1778 - Loss: 0.2437, Accuracy: 0.9076\n",
      "  Batch 770/1778 - Loss: 0.2437, Accuracy: 0.9076\n",
      "  Batch 780/1778 - Loss: 0.2447, Accuracy: 0.9073\n",
      "  Batch 790/1778 - Loss: 0.2446, Accuracy: 0.9074\n",
      "  Batch 800/1778 - Loss: 0.2440, Accuracy: 0.9077\n",
      "  Batch 810/1778 - Loss: 0.2433, Accuracy: 0.9078\n",
      "  Batch 820/1778 - Loss: 0.2430, Accuracy: 0.9081\n",
      "  Batch 830/1778 - Loss: 0.2433, Accuracy: 0.9078\n",
      "  Batch 840/1778 - Loss: 0.2436, Accuracy: 0.9078\n",
      "  Batch 850/1778 - Loss: 0.2437, Accuracy: 0.9076\n",
      "  Batch 860/1778 - Loss: 0.2436, Accuracy: 0.9076\n",
      "  Batch 870/1778 - Loss: 0.2433, Accuracy: 0.9077\n",
      "  Batch 880/1778 - Loss: 0.2429, Accuracy: 0.9080\n",
      "  Batch 890/1778 - Loss: 0.2429, Accuracy: 0.9079\n",
      "  Batch 900/1778 - Loss: 0.2431, Accuracy: 0.9078\n",
      "  Batch 910/1778 - Loss: 0.2432, Accuracy: 0.9077\n",
      "  Batch 920/1778 - Loss: 0.2433, Accuracy: 0.9078\n",
      "  Batch 930/1778 - Loss: 0.2434, Accuracy: 0.9078\n",
      "  Batch 940/1778 - Loss: 0.2430, Accuracy: 0.9081\n",
      "  Batch 950/1778 - Loss: 0.2430, Accuracy: 0.9081\n",
      "  Batch 960/1778 - Loss: 0.2437, Accuracy: 0.9078\n",
      "  Batch 970/1778 - Loss: 0.2434, Accuracy: 0.9079\n",
      "  Batch 980/1778 - Loss: 0.2432, Accuracy: 0.9080\n",
      "  Batch 990/1778 - Loss: 0.2434, Accuracy: 0.9081\n",
      "  Batch 1000/1778 - Loss: 0.2433, Accuracy: 0.9082\n",
      "  Batch 1010/1778 - Loss: 0.2442, Accuracy: 0.9081\n",
      "  Batch 1020/1778 - Loss: 0.2444, Accuracy: 0.9081\n",
      "  Batch 1030/1778 - Loss: 0.2446, Accuracy: 0.9082\n",
      "  Batch 1040/1778 - Loss: 0.2447, Accuracy: 0.9082\n",
      "  Batch 1050/1778 - Loss: 0.2450, Accuracy: 0.9080\n",
      "  Batch 1060/1778 - Loss: 0.2448, Accuracy: 0.9083\n",
      "  Batch 1070/1778 - Loss: 0.2450, Accuracy: 0.9083\n",
      "  Batch 1080/1778 - Loss: 0.2448, Accuracy: 0.9085\n",
      "  Batch 1090/1778 - Loss: 0.2458, Accuracy: 0.9081\n",
      "  Batch 1100/1778 - Loss: 0.2457, Accuracy: 0.9081\n",
      "  Batch 1110/1778 - Loss: 0.2456, Accuracy: 0.9081\n",
      "  Batch 1120/1778 - Loss: 0.2458, Accuracy: 0.9080\n",
      "  Batch 1130/1778 - Loss: 0.2458, Accuracy: 0.9080\n",
      "  Batch 1140/1778 - Loss: 0.2453, Accuracy: 0.9081\n",
      "  Batch 1150/1778 - Loss: 0.2452, Accuracy: 0.9082\n",
      "  Batch 1160/1778 - Loss: 0.2453, Accuracy: 0.9083\n",
      "  Batch 1170/1778 - Loss: 0.2453, Accuracy: 0.9083\n",
      "  Batch 1180/1778 - Loss: 0.2451, Accuracy: 0.9082\n",
      "  Batch 1190/1778 - Loss: 0.2453, Accuracy: 0.9082\n",
      "  Batch 1200/1778 - Loss: 0.2450, Accuracy: 0.9083\n",
      "  Batch 1210/1778 - Loss: 0.2452, Accuracy: 0.9083\n",
      "  Batch 1220/1778 - Loss: 0.2448, Accuracy: 0.9085\n",
      "  Batch 1230/1778 - Loss: 0.2445, Accuracy: 0.9085\n",
      "  Batch 1240/1778 - Loss: 0.2444, Accuracy: 0.9085\n",
      "  Batch 1250/1778 - Loss: 0.2442, Accuracy: 0.9086\n",
      "  Batch 1260/1778 - Loss: 0.2441, Accuracy: 0.9085\n",
      "  Batch 1270/1778 - Loss: 0.2439, Accuracy: 0.9085\n",
      "  Batch 1280/1778 - Loss: 0.2441, Accuracy: 0.9085\n",
      "  Batch 1290/1778 - Loss: 0.2439, Accuracy: 0.9086\n",
      "  Batch 1300/1778 - Loss: 0.2440, Accuracy: 0.9085\n",
      "  Batch 1310/1778 - Loss: 0.2439, Accuracy: 0.9086\n",
      "  Batch 1320/1778 - Loss: 0.2440, Accuracy: 0.9085\n",
      "  Batch 1330/1778 - Loss: 0.2439, Accuracy: 0.9086\n",
      "  Batch 1340/1778 - Loss: 0.2446, Accuracy: 0.9083\n",
      "  Batch 1350/1778 - Loss: 0.2448, Accuracy: 0.9082\n",
      "  Batch 1360/1778 - Loss: 0.2451, Accuracy: 0.9081\n",
      "  Batch 1370/1778 - Loss: 0.2451, Accuracy: 0.9081\n",
      "  Batch 1380/1778 - Loss: 0.2450, Accuracy: 0.9082\n",
      "  Batch 1390/1778 - Loss: 0.2450, Accuracy: 0.9081\n",
      "  Batch 1400/1778 - Loss: 0.2452, Accuracy: 0.9081\n",
      "  Batch 1410/1778 - Loss: 0.2453, Accuracy: 0.9080\n",
      "  Batch 1420/1778 - Loss: 0.2455, Accuracy: 0.9079\n",
      "  Batch 1430/1778 - Loss: 0.2455, Accuracy: 0.9079\n",
      "  Batch 1440/1778 - Loss: 0.2455, Accuracy: 0.9080\n",
      "  Batch 1450/1778 - Loss: 0.2457, Accuracy: 0.9080\n",
      "  Batch 1460/1778 - Loss: 0.2460, Accuracy: 0.9077\n",
      "  Batch 1470/1778 - Loss: 0.2461, Accuracy: 0.9077\n",
      "  Batch 1480/1778 - Loss: 0.2460, Accuracy: 0.9077\n",
      "  Batch 1490/1778 - Loss: 0.2462, Accuracy: 0.9077\n",
      "  Batch 1500/1778 - Loss: 0.2461, Accuracy: 0.9077\n",
      "  Batch 1510/1778 - Loss: 0.2459, Accuracy: 0.9078\n",
      "  Batch 1520/1778 - Loss: 0.2459, Accuracy: 0.9078\n",
      "  Batch 1530/1778 - Loss: 0.2457, Accuracy: 0.9079\n",
      "  Batch 1540/1778 - Loss: 0.2457, Accuracy: 0.9079\n",
      "  Batch 1550/1778 - Loss: 0.2459, Accuracy: 0.9079\n",
      "  Batch 1560/1778 - Loss: 0.2455, Accuracy: 0.9081\n",
      "  Batch 1570/1778 - Loss: 0.2454, Accuracy: 0.9082\n",
      "  Batch 1580/1778 - Loss: 0.2453, Accuracy: 0.9082\n",
      "  Batch 1590/1778 - Loss: 0.2454, Accuracy: 0.9082\n",
      "  Batch 1600/1778 - Loss: 0.2455, Accuracy: 0.9081\n",
      "  Batch 1610/1778 - Loss: 0.2458, Accuracy: 0.9081\n",
      "  Batch 1620/1778 - Loss: 0.2463, Accuracy: 0.9079\n",
      "  Batch 1630/1778 - Loss: 0.2466, Accuracy: 0.9079\n",
      "  Batch 1640/1778 - Loss: 0.2466, Accuracy: 0.9079\n",
      "  Batch 1650/1778 - Loss: 0.2466, Accuracy: 0.9079\n",
      "  Batch 1660/1778 - Loss: 0.2468, Accuracy: 0.9080\n",
      "  Batch 1670/1778 - Loss: 0.2465, Accuracy: 0.9081\n",
      "  Batch 1680/1778 - Loss: 0.2466, Accuracy: 0.9080\n",
      "  Batch 1690/1778 - Loss: 0.2466, Accuracy: 0.9080\n",
      "  Batch 1700/1778 - Loss: 0.2467, Accuracy: 0.9080\n",
      "  Batch 1710/1778 - Loss: 0.2464, Accuracy: 0.9081\n",
      "  Batch 1720/1778 - Loss: 0.2460, Accuracy: 0.9082\n",
      "  Batch 1730/1778 - Loss: 0.2460, Accuracy: 0.9082\n",
      "  Batch 1740/1778 - Loss: 0.2458, Accuracy: 0.9083\n",
      "  Batch 1750/1778 - Loss: 0.2456, Accuracy: 0.9084\n",
      "  Batch 1760/1778 - Loss: 0.2458, Accuracy: 0.9084\n",
      "  Batch 1770/1778 - Loss: 0.2459, Accuracy: 0.9085\n",
      "\n",
      "Kết quả Epoch 7:\n",
      "  Loss trung bình: 0.2462\n",
      "  Độ chính xác trung bình: 0.9084\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 8 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.1617, Accuracy: 0.9290\n",
      "  Batch 20/1778 - Loss: 0.2034, Accuracy: 0.9241\n",
      "  Batch 30/1778 - Loss: 0.2281, Accuracy: 0.9143\n",
      "  Batch 40/1778 - Loss: 0.2383, Accuracy: 0.9116\n",
      "  Batch 50/1778 - Loss: 0.2256, Accuracy: 0.9161\n",
      "  Batch 60/1778 - Loss: 0.2267, Accuracy: 0.9170\n",
      "  Batch 70/1778 - Loss: 0.2240, Accuracy: 0.9177\n",
      "  Batch 80/1778 - Loss: 0.2164, Accuracy: 0.9198\n",
      "  Batch 90/1778 - Loss: 0.2186, Accuracy: 0.9190\n",
      "  Batch 100/1778 - Loss: 0.2155, Accuracy: 0.9192\n",
      "  Batch 110/1778 - Loss: 0.2114, Accuracy: 0.9212\n",
      "  Batch 120/1778 - Loss: 0.2101, Accuracy: 0.9220\n",
      "  Batch 130/1778 - Loss: 0.2080, Accuracy: 0.9229\n",
      "  Batch 140/1778 - Loss: 0.2123, Accuracy: 0.9215\n",
      "  Batch 150/1778 - Loss: 0.2185, Accuracy: 0.9187\n",
      "  Batch 160/1778 - Loss: 0.2196, Accuracy: 0.9181\n",
      "  Batch 170/1778 - Loss: 0.2224, Accuracy: 0.9165\n",
      "  Batch 180/1778 - Loss: 0.2223, Accuracy: 0.9168\n",
      "  Batch 190/1778 - Loss: 0.2228, Accuracy: 0.9164\n",
      "  Batch 200/1778 - Loss: 0.2216, Accuracy: 0.9170\n",
      "  Batch 210/1778 - Loss: 0.2219, Accuracy: 0.9169\n",
      "  Batch 220/1778 - Loss: 0.2206, Accuracy: 0.9170\n",
      "  Batch 230/1778 - Loss: 0.2197, Accuracy: 0.9175\n",
      "  Batch 240/1778 - Loss: 0.2212, Accuracy: 0.9171\n",
      "  Batch 250/1778 - Loss: 0.2222, Accuracy: 0.9165\n",
      "  Batch 260/1778 - Loss: 0.2220, Accuracy: 0.9165\n",
      "  Batch 270/1778 - Loss: 0.2226, Accuracy: 0.9169\n",
      "  Batch 280/1778 - Loss: 0.2224, Accuracy: 0.9168\n",
      "  Batch 290/1778 - Loss: 0.2213, Accuracy: 0.9167\n",
      "  Batch 300/1778 - Loss: 0.2218, Accuracy: 0.9167\n",
      "  Batch 310/1778 - Loss: 0.2218, Accuracy: 0.9161\n",
      "  Batch 320/1778 - Loss: 0.2238, Accuracy: 0.9155\n",
      "  Batch 330/1778 - Loss: 0.2232, Accuracy: 0.9159\n",
      "  Batch 340/1778 - Loss: 0.2238, Accuracy: 0.9156\n",
      "  Batch 350/1778 - Loss: 0.2231, Accuracy: 0.9156\n",
      "  Batch 360/1778 - Loss: 0.2236, Accuracy: 0.9153\n",
      "  Batch 370/1778 - Loss: 0.2222, Accuracy: 0.9158\n",
      "  Batch 380/1778 - Loss: 0.2225, Accuracy: 0.9160\n",
      "  Batch 390/1778 - Loss: 0.2229, Accuracy: 0.9162\n",
      "  Batch 400/1778 - Loss: 0.2245, Accuracy: 0.9156\n",
      "  Batch 410/1778 - Loss: 0.2247, Accuracy: 0.9155\n",
      "  Batch 420/1778 - Loss: 0.2240, Accuracy: 0.9156\n",
      "  Batch 430/1778 - Loss: 0.2247, Accuracy: 0.9152\n",
      "  Batch 440/1778 - Loss: 0.2244, Accuracy: 0.9151\n",
      "  Batch 450/1778 - Loss: 0.2245, Accuracy: 0.9153\n",
      "  Batch 460/1778 - Loss: 0.2244, Accuracy: 0.9154\n",
      "  Batch 470/1778 - Loss: 0.2240, Accuracy: 0.9155\n",
      "  Batch 480/1778 - Loss: 0.2229, Accuracy: 0.9159\n",
      "  Batch 490/1778 - Loss: 0.2243, Accuracy: 0.9159\n",
      "  Batch 500/1778 - Loss: 0.2242, Accuracy: 0.9161\n",
      "  Batch 510/1778 - Loss: 0.2242, Accuracy: 0.9160\n",
      "  Batch 520/1778 - Loss: 0.2247, Accuracy: 0.9160\n",
      "  Batch 530/1778 - Loss: 0.2246, Accuracy: 0.9159\n",
      "  Batch 540/1778 - Loss: 0.2243, Accuracy: 0.9160\n",
      "  Batch 550/1778 - Loss: 0.2261, Accuracy: 0.9153\n",
      "  Batch 560/1778 - Loss: 0.2265, Accuracy: 0.9153\n",
      "  Batch 570/1778 - Loss: 0.2261, Accuracy: 0.9154\n",
      "  Batch 580/1778 - Loss: 0.2258, Accuracy: 0.9156\n",
      "  Batch 590/1778 - Loss: 0.2269, Accuracy: 0.9150\n",
      "  Batch 600/1778 - Loss: 0.2271, Accuracy: 0.9147\n",
      "  Batch 610/1778 - Loss: 0.2273, Accuracy: 0.9148\n",
      "  Batch 620/1778 - Loss: 0.2279, Accuracy: 0.9147\n",
      "  Batch 630/1778 - Loss: 0.2285, Accuracy: 0.9144\n",
      "  Batch 640/1778 - Loss: 0.2282, Accuracy: 0.9142\n",
      "  Batch 650/1778 - Loss: 0.2278, Accuracy: 0.9144\n",
      "  Batch 660/1778 - Loss: 0.2280, Accuracy: 0.9144\n",
      "  Batch 670/1778 - Loss: 0.2273, Accuracy: 0.9146\n",
      "  Batch 680/1778 - Loss: 0.2275, Accuracy: 0.9146\n",
      "  Batch 690/1778 - Loss: 0.2270, Accuracy: 0.9148\n",
      "  Batch 700/1778 - Loss: 0.2269, Accuracy: 0.9147\n",
      "  Batch 710/1778 - Loss: 0.2261, Accuracy: 0.9151\n",
      "  Batch 720/1778 - Loss: 0.2258, Accuracy: 0.9152\n",
      "  Batch 730/1778 - Loss: 0.2256, Accuracy: 0.9150\n",
      "  Batch 740/1778 - Loss: 0.2265, Accuracy: 0.9146\n",
      "  Batch 750/1778 - Loss: 0.2260, Accuracy: 0.9148\n",
      "  Batch 760/1778 - Loss: 0.2253, Accuracy: 0.9150\n",
      "  Batch 770/1778 - Loss: 0.2258, Accuracy: 0.9148\n",
      "  Batch 780/1778 - Loss: 0.2260, Accuracy: 0.9148\n",
      "  Batch 790/1778 - Loss: 0.2264, Accuracy: 0.9148\n",
      "  Batch 800/1778 - Loss: 0.2263, Accuracy: 0.9149\n",
      "  Batch 810/1778 - Loss: 0.2265, Accuracy: 0.9148\n",
      "  Batch 820/1778 - Loss: 0.2270, Accuracy: 0.9147\n",
      "  Batch 830/1778 - Loss: 0.2266, Accuracy: 0.9148\n",
      "  Batch 840/1778 - Loss: 0.2260, Accuracy: 0.9149\n",
      "  Batch 850/1778 - Loss: 0.2260, Accuracy: 0.9148\n",
      "  Batch 860/1778 - Loss: 0.2248, Accuracy: 0.9153\n",
      "  Batch 870/1778 - Loss: 0.2248, Accuracy: 0.9152\n",
      "  Batch 880/1778 - Loss: 0.2252, Accuracy: 0.9150\n",
      "  Batch 890/1778 - Loss: 0.2246, Accuracy: 0.9152\n",
      "  Batch 900/1778 - Loss: 0.2252, Accuracy: 0.9149\n",
      "  Batch 910/1778 - Loss: 0.2254, Accuracy: 0.9150\n",
      "  Batch 920/1778 - Loss: 0.2256, Accuracy: 0.9149\n",
      "  Batch 930/1778 - Loss: 0.2261, Accuracy: 0.9148\n",
      "  Batch 940/1778 - Loss: 0.2265, Accuracy: 0.9146\n",
      "  Batch 950/1778 - Loss: 0.2266, Accuracy: 0.9146\n",
      "  Batch 960/1778 - Loss: 0.2272, Accuracy: 0.9143\n",
      "  Batch 970/1778 - Loss: 0.2272, Accuracy: 0.9142\n",
      "  Batch 980/1778 - Loss: 0.2268, Accuracy: 0.9145\n",
      "  Batch 990/1778 - Loss: 0.2268, Accuracy: 0.9145\n",
      "  Batch 1000/1778 - Loss: 0.2264, Accuracy: 0.9147\n",
      "  Batch 1010/1778 - Loss: 0.2267, Accuracy: 0.9146\n",
      "  Batch 1020/1778 - Loss: 0.2269, Accuracy: 0.9145\n",
      "  Batch 1030/1778 - Loss: 0.2269, Accuracy: 0.9146\n",
      "  Batch 1040/1778 - Loss: 0.2276, Accuracy: 0.9143\n",
      "  Batch 1050/1778 - Loss: 0.2273, Accuracy: 0.9144\n",
      "  Batch 1060/1778 - Loss: 0.2271, Accuracy: 0.9147\n",
      "  Batch 1070/1778 - Loss: 0.2270, Accuracy: 0.9149\n",
      "  Batch 1080/1778 - Loss: 0.2269, Accuracy: 0.9149\n",
      "  Batch 1090/1778 - Loss: 0.2272, Accuracy: 0.9147\n",
      "  Batch 1100/1778 - Loss: 0.2279, Accuracy: 0.9144\n",
      "  Batch 1110/1778 - Loss: 0.2281, Accuracy: 0.9143\n",
      "  Batch 1120/1778 - Loss: 0.2280, Accuracy: 0.9145\n",
      "  Batch 1130/1778 - Loss: 0.2282, Accuracy: 0.9143\n",
      "  Batch 1140/1778 - Loss: 0.2275, Accuracy: 0.9146\n",
      "  Batch 1150/1778 - Loss: 0.2274, Accuracy: 0.9145\n",
      "  Batch 1160/1778 - Loss: 0.2279, Accuracy: 0.9144\n",
      "  Batch 1170/1778 - Loss: 0.2274, Accuracy: 0.9145\n",
      "  Batch 1180/1778 - Loss: 0.2274, Accuracy: 0.9147\n",
      "  Batch 1190/1778 - Loss: 0.2271, Accuracy: 0.9147\n",
      "  Batch 1200/1778 - Loss: 0.2272, Accuracy: 0.9147\n",
      "  Batch 1210/1778 - Loss: 0.2270, Accuracy: 0.9146\n",
      "  Batch 1220/1778 - Loss: 0.2275, Accuracy: 0.9145\n",
      "  Batch 1230/1778 - Loss: 0.2280, Accuracy: 0.9141\n",
      "  Batch 1240/1778 - Loss: 0.2284, Accuracy: 0.9141\n",
      "  Batch 1250/1778 - Loss: 0.2281, Accuracy: 0.9142\n",
      "  Batch 1260/1778 - Loss: 0.2279, Accuracy: 0.9142\n",
      "  Batch 1270/1778 - Loss: 0.2278, Accuracy: 0.9141\n",
      "  Batch 1280/1778 - Loss: 0.2274, Accuracy: 0.9144\n",
      "  Batch 1290/1778 - Loss: 0.2273, Accuracy: 0.9144\n",
      "  Batch 1300/1778 - Loss: 0.2270, Accuracy: 0.9145\n",
      "  Batch 1310/1778 - Loss: 0.2274, Accuracy: 0.9145\n",
      "  Batch 1320/1778 - Loss: 0.2271, Accuracy: 0.9145\n",
      "  Batch 1330/1778 - Loss: 0.2274, Accuracy: 0.9143\n",
      "  Batch 1340/1778 - Loss: 0.2272, Accuracy: 0.9144\n",
      "  Batch 1350/1778 - Loss: 0.2274, Accuracy: 0.9142\n",
      "  Batch 1360/1778 - Loss: 0.2273, Accuracy: 0.9144\n",
      "  Batch 1370/1778 - Loss: 0.2272, Accuracy: 0.9144\n",
      "  Batch 1380/1778 - Loss: 0.2272, Accuracy: 0.9145\n",
      "  Batch 1390/1778 - Loss: 0.2272, Accuracy: 0.9144\n",
      "  Batch 1400/1778 - Loss: 0.2269, Accuracy: 0.9146\n",
      "  Batch 1410/1778 - Loss: 0.2268, Accuracy: 0.9145\n",
      "  Batch 1420/1778 - Loss: 0.2273, Accuracy: 0.9143\n",
      "  Batch 1430/1778 - Loss: 0.2275, Accuracy: 0.9144\n",
      "  Batch 1440/1778 - Loss: 0.2274, Accuracy: 0.9144\n",
      "  Batch 1450/1778 - Loss: 0.2273, Accuracy: 0.9145\n",
      "  Batch 1460/1778 - Loss: 0.2269, Accuracy: 0.9145\n",
      "  Batch 1470/1778 - Loss: 0.2266, Accuracy: 0.9147\n",
      "  Batch 1480/1778 - Loss: 0.2266, Accuracy: 0.9146\n",
      "  Batch 1490/1778 - Loss: 0.2266, Accuracy: 0.9147\n",
      "  Batch 1500/1778 - Loss: 0.2270, Accuracy: 0.9146\n",
      "  Batch 1510/1778 - Loss: 0.2270, Accuracy: 0.9145\n",
      "  Batch 1520/1778 - Loss: 0.2270, Accuracy: 0.9144\n",
      "  Batch 1530/1778 - Loss: 0.2271, Accuracy: 0.9144\n",
      "  Batch 1540/1778 - Loss: 0.2270, Accuracy: 0.9144\n",
      "  Batch 1550/1778 - Loss: 0.2271, Accuracy: 0.9144\n",
      "  Batch 1560/1778 - Loss: 0.2273, Accuracy: 0.9144\n",
      "  Batch 1570/1778 - Loss: 0.2272, Accuracy: 0.9144\n",
      "  Batch 1580/1778 - Loss: 0.2272, Accuracy: 0.9144\n",
      "  Batch 1590/1778 - Loss: 0.2270, Accuracy: 0.9144\n",
      "  Batch 1600/1778 - Loss: 0.2266, Accuracy: 0.9145\n",
      "  Batch 1610/1778 - Loss: 0.2267, Accuracy: 0.9145\n",
      "  Batch 1620/1778 - Loss: 0.2269, Accuracy: 0.9143\n",
      "  Batch 1630/1778 - Loss: 0.2271, Accuracy: 0.9142\n",
      "  Batch 1640/1778 - Loss: 0.2269, Accuracy: 0.9142\n",
      "  Batch 1650/1778 - Loss: 0.2270, Accuracy: 0.9141\n",
      "  Batch 1660/1778 - Loss: 0.2270, Accuracy: 0.9141\n",
      "  Batch 1670/1778 - Loss: 0.2269, Accuracy: 0.9141\n",
      "  Batch 1680/1778 - Loss: 0.2270, Accuracy: 0.9141\n",
      "  Batch 1690/1778 - Loss: 0.2273, Accuracy: 0.9140\n",
      "  Batch 1700/1778 - Loss: 0.2272, Accuracy: 0.9142\n",
      "  Batch 1710/1778 - Loss: 0.2269, Accuracy: 0.9143\n",
      "  Batch 1720/1778 - Loss: 0.2270, Accuracy: 0.9142\n",
      "  Batch 1730/1778 - Loss: 0.2273, Accuracy: 0.9142\n",
      "  Batch 1740/1778 - Loss: 0.2270, Accuracy: 0.9143\n",
      "  Batch 1750/1778 - Loss: 0.2268, Accuracy: 0.9143\n",
      "  Batch 1760/1778 - Loss: 0.2269, Accuracy: 0.9144\n",
      "  Batch 1770/1778 - Loss: 0.2270, Accuracy: 0.9143\n",
      "\n",
      "Kết quả Epoch 8:\n",
      "  Loss trung bình: 0.2269\n",
      "  Độ chính xác trung bình: 0.9144\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 9 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.2531, Accuracy: 0.8807\n",
      "  Batch 20/1778 - Loss: 0.2176, Accuracy: 0.9003\n",
      "  Batch 30/1778 - Loss: 0.2020, Accuracy: 0.9143\n",
      "  Batch 40/1778 - Loss: 0.2023, Accuracy: 0.9162\n",
      "  Batch 50/1778 - Loss: 0.2136, Accuracy: 0.9136\n",
      "  Batch 60/1778 - Loss: 0.2231, Accuracy: 0.9119\n",
      "  Batch 70/1778 - Loss: 0.2126, Accuracy: 0.9159\n",
      "  Batch 80/1778 - Loss: 0.2062, Accuracy: 0.9190\n",
      "  Batch 90/1778 - Loss: 0.2020, Accuracy: 0.9220\n",
      "  Batch 100/1778 - Loss: 0.2005, Accuracy: 0.9233\n",
      "  Batch 110/1778 - Loss: 0.2017, Accuracy: 0.9234\n",
      "  Batch 120/1778 - Loss: 0.2118, Accuracy: 0.9194\n",
      "  Batch 130/1778 - Loss: 0.2084, Accuracy: 0.9215\n",
      "  Batch 140/1778 - Loss: 0.2055, Accuracy: 0.9222\n",
      "  Batch 150/1778 - Loss: 0.2078, Accuracy: 0.9207\n",
      "  Batch 160/1778 - Loss: 0.2081, Accuracy: 0.9214\n",
      "  Batch 170/1778 - Loss: 0.2076, Accuracy: 0.9212\n",
      "  Batch 180/1778 - Loss: 0.2083, Accuracy: 0.9214\n",
      "  Batch 190/1778 - Loss: 0.2088, Accuracy: 0.9215\n",
      "  Batch 200/1778 - Loss: 0.2099, Accuracy: 0.9213\n",
      "  Batch 210/1778 - Loss: 0.2097, Accuracy: 0.9217\n",
      "  Batch 220/1778 - Loss: 0.2106, Accuracy: 0.9214\n",
      "  Batch 230/1778 - Loss: 0.2116, Accuracy: 0.9213\n",
      "  Batch 240/1778 - Loss: 0.2105, Accuracy: 0.9218\n",
      "  Batch 250/1778 - Loss: 0.2104, Accuracy: 0.9217\n",
      "  Batch 260/1778 - Loss: 0.2093, Accuracy: 0.9219\n",
      "  Batch 270/1778 - Loss: 0.2102, Accuracy: 0.9214\n",
      "  Batch 280/1778 - Loss: 0.2097, Accuracy: 0.9217\n",
      "  Batch 290/1778 - Loss: 0.2109, Accuracy: 0.9209\n",
      "  Batch 300/1778 - Loss: 0.2111, Accuracy: 0.9210\n",
      "  Batch 310/1778 - Loss: 0.2113, Accuracy: 0.9206\n",
      "  Batch 320/1778 - Loss: 0.2114, Accuracy: 0.9209\n",
      "  Batch 330/1778 - Loss: 0.2116, Accuracy: 0.9207\n",
      "  Batch 340/1778 - Loss: 0.2122, Accuracy: 0.9207\n",
      "  Batch 350/1778 - Loss: 0.2132, Accuracy: 0.9200\n",
      "  Batch 360/1778 - Loss: 0.2127, Accuracy: 0.9205\n",
      "  Batch 370/1778 - Loss: 0.2137, Accuracy: 0.9203\n",
      "  Batch 380/1778 - Loss: 0.2130, Accuracy: 0.9205\n",
      "  Batch 390/1778 - Loss: 0.2112, Accuracy: 0.9211\n",
      "  Batch 400/1778 - Loss: 0.2118, Accuracy: 0.9211\n",
      "  Batch 410/1778 - Loss: 0.2113, Accuracy: 0.9217\n",
      "  Batch 420/1778 - Loss: 0.2111, Accuracy: 0.9218\n",
      "  Batch 430/1778 - Loss: 0.2104, Accuracy: 0.9220\n",
      "  Batch 440/1778 - Loss: 0.2124, Accuracy: 0.9213\n",
      "  Batch 450/1778 - Loss: 0.2123, Accuracy: 0.9216\n",
      "  Batch 460/1778 - Loss: 0.2139, Accuracy: 0.9210\n",
      "  Batch 470/1778 - Loss: 0.2136, Accuracy: 0.9210\n",
      "  Batch 480/1778 - Loss: 0.2138, Accuracy: 0.9212\n",
      "  Batch 490/1778 - Loss: 0.2142, Accuracy: 0.9211\n",
      "  Batch 500/1778 - Loss: 0.2138, Accuracy: 0.9212\n",
      "  Batch 510/1778 - Loss: 0.2128, Accuracy: 0.9218\n",
      "  Batch 520/1778 - Loss: 0.2122, Accuracy: 0.9219\n",
      "  Batch 530/1778 - Loss: 0.2121, Accuracy: 0.9218\n",
      "  Batch 540/1778 - Loss: 0.2122, Accuracy: 0.9217\n",
      "  Batch 550/1778 - Loss: 0.2114, Accuracy: 0.9221\n",
      "  Batch 560/1778 - Loss: 0.2114, Accuracy: 0.9221\n",
      "  Batch 570/1778 - Loss: 0.2114, Accuracy: 0.9221\n",
      "  Batch 580/1778 - Loss: 0.2118, Accuracy: 0.9217\n",
      "  Batch 590/1778 - Loss: 0.2115, Accuracy: 0.9218\n",
      "  Batch 600/1778 - Loss: 0.2116, Accuracy: 0.9218\n",
      "  Batch 610/1778 - Loss: 0.2128, Accuracy: 0.9214\n",
      "  Batch 620/1778 - Loss: 0.2123, Accuracy: 0.9216\n",
      "  Batch 630/1778 - Loss: 0.2118, Accuracy: 0.9216\n",
      "  Batch 640/1778 - Loss: 0.2109, Accuracy: 0.9217\n",
      "  Batch 650/1778 - Loss: 0.2111, Accuracy: 0.9221\n",
      "  Batch 660/1778 - Loss: 0.2106, Accuracy: 0.9223\n",
      "  Batch 670/1778 - Loss: 0.2108, Accuracy: 0.9220\n",
      "  Batch 680/1778 - Loss: 0.2103, Accuracy: 0.9223\n",
      "  Batch 690/1778 - Loss: 0.2106, Accuracy: 0.9223\n",
      "  Batch 700/1778 - Loss: 0.2107, Accuracy: 0.9222\n",
      "  Batch 710/1778 - Loss: 0.2103, Accuracy: 0.9225\n",
      "  Batch 720/1778 - Loss: 0.2114, Accuracy: 0.9222\n",
      "  Batch 730/1778 - Loss: 0.2119, Accuracy: 0.9218\n",
      "  Batch 740/1778 - Loss: 0.2117, Accuracy: 0.9219\n",
      "  Batch 750/1778 - Loss: 0.2112, Accuracy: 0.9222\n",
      "  Batch 760/1778 - Loss: 0.2105, Accuracy: 0.9225\n",
      "  Batch 770/1778 - Loss: 0.2109, Accuracy: 0.9223\n",
      "  Batch 780/1778 - Loss: 0.2112, Accuracy: 0.9221\n",
      "  Batch 790/1778 - Loss: 0.2106, Accuracy: 0.9224\n",
      "  Batch 800/1778 - Loss: 0.2121, Accuracy: 0.9221\n",
      "  Batch 810/1778 - Loss: 0.2130, Accuracy: 0.9217\n",
      "  Batch 820/1778 - Loss: 0.2125, Accuracy: 0.9218\n",
      "  Batch 830/1778 - Loss: 0.2119, Accuracy: 0.9219\n",
      "  Batch 840/1778 - Loss: 0.2116, Accuracy: 0.9220\n",
      "  Batch 850/1778 - Loss: 0.2113, Accuracy: 0.9222\n",
      "  Batch 860/1778 - Loss: 0.2112, Accuracy: 0.9222\n",
      "  Batch 870/1778 - Loss: 0.2111, Accuracy: 0.9222\n",
      "  Batch 880/1778 - Loss: 0.2115, Accuracy: 0.9220\n",
      "  Batch 890/1778 - Loss: 0.2113, Accuracy: 0.9221\n",
      "  Batch 900/1778 - Loss: 0.2110, Accuracy: 0.9223\n",
      "  Batch 910/1778 - Loss: 0.2111, Accuracy: 0.9224\n",
      "  Batch 920/1778 - Loss: 0.2110, Accuracy: 0.9225\n",
      "  Batch 930/1778 - Loss: 0.2108, Accuracy: 0.9225\n",
      "  Batch 940/1778 - Loss: 0.2114, Accuracy: 0.9224\n",
      "  Batch 950/1778 - Loss: 0.2110, Accuracy: 0.9224\n",
      "  Batch 960/1778 - Loss: 0.2110, Accuracy: 0.9222\n",
      "  Batch 970/1778 - Loss: 0.2105, Accuracy: 0.9225\n",
      "  Batch 980/1778 - Loss: 0.2097, Accuracy: 0.9228\n",
      "  Batch 990/1778 - Loss: 0.2097, Accuracy: 0.9229\n",
      "  Batch 1000/1778 - Loss: 0.2093, Accuracy: 0.9230\n",
      "  Batch 1010/1778 - Loss: 0.2090, Accuracy: 0.9230\n",
      "  Batch 1020/1778 - Loss: 0.2087, Accuracy: 0.9231\n",
      "  Batch 1030/1778 - Loss: 0.2086, Accuracy: 0.9231\n",
      "  Batch 1040/1778 - Loss: 0.2087, Accuracy: 0.9232\n",
      "  Batch 1050/1778 - Loss: 0.2088, Accuracy: 0.9230\n",
      "  Batch 1060/1778 - Loss: 0.2087, Accuracy: 0.9230\n",
      "  Batch 1070/1778 - Loss: 0.2089, Accuracy: 0.9229\n",
      "  Batch 1080/1778 - Loss: 0.2085, Accuracy: 0.9230\n",
      "  Batch 1090/1778 - Loss: 0.2082, Accuracy: 0.9232\n",
      "  Batch 1100/1778 - Loss: 0.2080, Accuracy: 0.9233\n",
      "  Batch 1110/1778 - Loss: 0.2075, Accuracy: 0.9233\n",
      "  Batch 1120/1778 - Loss: 0.2073, Accuracy: 0.9233\n",
      "  Batch 1130/1778 - Loss: 0.2083, Accuracy: 0.9229\n",
      "  Batch 1140/1778 - Loss: 0.2079, Accuracy: 0.9231\n",
      "  Batch 1150/1778 - Loss: 0.2078, Accuracy: 0.9231\n",
      "  Batch 1160/1778 - Loss: 0.2071, Accuracy: 0.9233\n",
      "  Batch 1170/1778 - Loss: 0.2072, Accuracy: 0.9235\n",
      "  Batch 1180/1778 - Loss: 0.2078, Accuracy: 0.9233\n",
      "  Batch 1190/1778 - Loss: 0.2072, Accuracy: 0.9235\n",
      "  Batch 1200/1778 - Loss: 0.2071, Accuracy: 0.9236\n",
      "  Batch 1210/1778 - Loss: 0.2071, Accuracy: 0.9235\n",
      "  Batch 1220/1778 - Loss: 0.2067, Accuracy: 0.9236\n",
      "  Batch 1230/1778 - Loss: 0.2066, Accuracy: 0.9236\n",
      "  Batch 1240/1778 - Loss: 0.2066, Accuracy: 0.9235\n",
      "  Batch 1250/1778 - Loss: 0.2067, Accuracy: 0.9234\n",
      "  Batch 1260/1778 - Loss: 0.2067, Accuracy: 0.9234\n",
      "  Batch 1270/1778 - Loss: 0.2067, Accuracy: 0.9233\n",
      "  Batch 1280/1778 - Loss: 0.2067, Accuracy: 0.9233\n",
      "  Batch 1290/1778 - Loss: 0.2068, Accuracy: 0.9232\n",
      "  Batch 1300/1778 - Loss: 0.2069, Accuracy: 0.9231\n",
      "  Batch 1310/1778 - Loss: 0.2071, Accuracy: 0.9230\n",
      "  Batch 1320/1778 - Loss: 0.2070, Accuracy: 0.9230\n",
      "  Batch 1330/1778 - Loss: 0.2068, Accuracy: 0.9231\n",
      "  Batch 1340/1778 - Loss: 0.2070, Accuracy: 0.9231\n",
      "  Batch 1350/1778 - Loss: 0.2070, Accuracy: 0.9232\n",
      "  Batch 1360/1778 - Loss: 0.2071, Accuracy: 0.9232\n",
      "  Batch 1370/1778 - Loss: 0.2070, Accuracy: 0.9233\n",
      "  Batch 1380/1778 - Loss: 0.2070, Accuracy: 0.9231\n",
      "  Batch 1390/1778 - Loss: 0.2072, Accuracy: 0.9231\n",
      "  Batch 1400/1778 - Loss: 0.2071, Accuracy: 0.9231\n",
      "  Batch 1410/1778 - Loss: 0.2072, Accuracy: 0.9231\n",
      "  Batch 1420/1778 - Loss: 0.2073, Accuracy: 0.9232\n",
      "  Batch 1430/1778 - Loss: 0.2074, Accuracy: 0.9231\n",
      "  Batch 1440/1778 - Loss: 0.2078, Accuracy: 0.9230\n",
      "  Batch 1450/1778 - Loss: 0.2076, Accuracy: 0.9230\n",
      "  Batch 1460/1778 - Loss: 0.2078, Accuracy: 0.9230\n",
      "  Batch 1470/1778 - Loss: 0.2077, Accuracy: 0.9229\n",
      "  Batch 1480/1778 - Loss: 0.2080, Accuracy: 0.9228\n",
      "  Batch 1490/1778 - Loss: 0.2084, Accuracy: 0.9227\n",
      "  Batch 1500/1778 - Loss: 0.2085, Accuracy: 0.9226\n",
      "  Batch 1510/1778 - Loss: 0.2084, Accuracy: 0.9227\n",
      "  Batch 1520/1778 - Loss: 0.2082, Accuracy: 0.9226\n",
      "  Batch 1530/1778 - Loss: 0.2078, Accuracy: 0.9228\n",
      "  Batch 1540/1778 - Loss: 0.2078, Accuracy: 0.9226\n",
      "  Batch 1550/1778 - Loss: 0.2076, Accuracy: 0.9227\n",
      "  Batch 1560/1778 - Loss: 0.2076, Accuracy: 0.9226\n",
      "  Batch 1570/1778 - Loss: 0.2074, Accuracy: 0.9227\n",
      "  Batch 1580/1778 - Loss: 0.2072, Accuracy: 0.9228\n",
      "  Batch 1590/1778 - Loss: 0.2075, Accuracy: 0.9227\n",
      "  Batch 1600/1778 - Loss: 0.2077, Accuracy: 0.9227\n",
      "  Batch 1610/1778 - Loss: 0.2080, Accuracy: 0.9226\n",
      "  Batch 1620/1778 - Loss: 0.2083, Accuracy: 0.9225\n",
      "  Batch 1630/1778 - Loss: 0.2085, Accuracy: 0.9224\n",
      "  Batch 1640/1778 - Loss: 0.2088, Accuracy: 0.9223\n",
      "  Batch 1650/1778 - Loss: 0.2088, Accuracy: 0.9224\n",
      "  Batch 1660/1778 - Loss: 0.2086, Accuracy: 0.9224\n",
      "  Batch 1670/1778 - Loss: 0.2087, Accuracy: 0.9224\n",
      "  Batch 1680/1778 - Loss: 0.2088, Accuracy: 0.9224\n",
      "  Batch 1690/1778 - Loss: 0.2091, Accuracy: 0.9223\n",
      "  Batch 1700/1778 - Loss: 0.2088, Accuracy: 0.9224\n",
      "  Batch 1710/1778 - Loss: 0.2089, Accuracy: 0.9223\n",
      "  Batch 1720/1778 - Loss: 0.2090, Accuracy: 0.9222\n",
      "  Batch 1730/1778 - Loss: 0.2091, Accuracy: 0.9222\n",
      "  Batch 1740/1778 - Loss: 0.2091, Accuracy: 0.9222\n",
      "  Batch 1750/1778 - Loss: 0.2091, Accuracy: 0.9222\n",
      "  Batch 1760/1778 - Loss: 0.2094, Accuracy: 0.9222\n",
      "  Batch 1770/1778 - Loss: 0.2093, Accuracy: 0.9222\n",
      "\n",
      "Kết quả Epoch 9:\n",
      "  Loss trung bình: 0.2094\n",
      "  Độ chính xác trung bình: 0.9222\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "\n",
      "===== Epoch 10 / 10 =====\n",
      "  Batch 10/1778 - Loss: 0.1897, Accuracy: 0.9261\n",
      "  Batch 20/1778 - Loss: 0.2116, Accuracy: 0.9211\n",
      "  Batch 30/1778 - Loss: 0.2129, Accuracy: 0.9194\n",
      "  Batch 40/1778 - Loss: 0.2062, Accuracy: 0.9223\n",
      "  Batch 50/1778 - Loss: 0.2022, Accuracy: 0.9252\n",
      "  Batch 60/1778 - Loss: 0.1990, Accuracy: 0.9262\n",
      "  Batch 70/1778 - Loss: 0.1968, Accuracy: 0.9265\n",
      "  Batch 80/1778 - Loss: 0.1988, Accuracy: 0.9252\n",
      "  Batch 90/1778 - Loss: 0.1898, Accuracy: 0.9286\n",
      "  Batch 100/1778 - Loss: 0.1936, Accuracy: 0.9288\n",
      "  Batch 110/1778 - Loss: 0.1928, Accuracy: 0.9293\n",
      "  Batch 120/1778 - Loss: 0.1900, Accuracy: 0.9298\n",
      "  Batch 130/1778 - Loss: 0.1955, Accuracy: 0.9280\n",
      "  Batch 140/1778 - Loss: 0.1962, Accuracy: 0.9275\n",
      "  Batch 150/1778 - Loss: 0.1994, Accuracy: 0.9257\n",
      "  Batch 160/1778 - Loss: 0.2014, Accuracy: 0.9253\n",
      "  Batch 170/1778 - Loss: 0.1988, Accuracy: 0.9267\n",
      "  Batch 180/1778 - Loss: 0.1981, Accuracy: 0.9271\n",
      "  Batch 190/1778 - Loss: 0.1986, Accuracy: 0.9278\n",
      "  Batch 200/1778 - Loss: 0.1947, Accuracy: 0.9289\n",
      "  Batch 210/1778 - Loss: 0.1933, Accuracy: 0.9294\n",
      "  Batch 220/1778 - Loss: 0.1968, Accuracy: 0.9273\n",
      "  Batch 230/1778 - Loss: 0.1967, Accuracy: 0.9272\n",
      "  Batch 240/1778 - Loss: 0.1994, Accuracy: 0.9273\n",
      "  Batch 250/1778 - Loss: 0.1982, Accuracy: 0.9275\n",
      "  Batch 260/1778 - Loss: 0.1989, Accuracy: 0.9274\n",
      "  Batch 270/1778 - Loss: 0.1983, Accuracy: 0.9278\n",
      "  Batch 280/1778 - Loss: 0.1984, Accuracy: 0.9280\n",
      "  Batch 290/1778 - Loss: 0.1982, Accuracy: 0.9285\n",
      "  Batch 300/1778 - Loss: 0.2009, Accuracy: 0.9276\n",
      "  Batch 310/1778 - Loss: 0.2013, Accuracy: 0.9273\n",
      "  Batch 320/1778 - Loss: 0.2024, Accuracy: 0.9265\n",
      "  Batch 330/1778 - Loss: 0.2003, Accuracy: 0.9272\n",
      "  Batch 340/1778 - Loss: 0.1999, Accuracy: 0.9271\n",
      "  Batch 350/1778 - Loss: 0.1990, Accuracy: 0.9277\n",
      "  Batch 360/1778 - Loss: 0.1986, Accuracy: 0.9280\n",
      "  Batch 370/1778 - Loss: 0.1985, Accuracy: 0.9276\n",
      "  Batch 380/1778 - Loss: 0.1988, Accuracy: 0.9276\n",
      "  Batch 390/1778 - Loss: 0.1981, Accuracy: 0.9276\n",
      "  Batch 400/1778 - Loss: 0.1980, Accuracy: 0.9276\n",
      "  Batch 410/1778 - Loss: 0.1964, Accuracy: 0.9281\n",
      "  Batch 420/1778 - Loss: 0.1967, Accuracy: 0.9281\n",
      "  Batch 430/1778 - Loss: 0.1948, Accuracy: 0.9289\n",
      "  Batch 440/1778 - Loss: 0.1956, Accuracy: 0.9285\n",
      "  Batch 450/1778 - Loss: 0.1965, Accuracy: 0.9284\n",
      "  Batch 460/1778 - Loss: 0.1963, Accuracy: 0.9287\n",
      "  Batch 470/1778 - Loss: 0.1963, Accuracy: 0.9284\n",
      "  Batch 480/1778 - Loss: 0.1957, Accuracy: 0.9286\n",
      "  Batch 490/1778 - Loss: 0.1955, Accuracy: 0.9287\n",
      "  Batch 500/1778 - Loss: 0.1964, Accuracy: 0.9286\n",
      "  Batch 510/1778 - Loss: 0.1973, Accuracy: 0.9282\n",
      "  Batch 520/1778 - Loss: 0.1978, Accuracy: 0.9276\n",
      "  Batch 530/1778 - Loss: 0.1972, Accuracy: 0.9276\n",
      "  Batch 540/1778 - Loss: 0.1975, Accuracy: 0.9274\n",
      "  Batch 550/1778 - Loss: 0.1978, Accuracy: 0.9271\n",
      "  Batch 560/1778 - Loss: 0.1981, Accuracy: 0.9270\n",
      "  Batch 570/1778 - Loss: 0.1984, Accuracy: 0.9268\n",
      "  Batch 580/1778 - Loss: 0.1993, Accuracy: 0.9266\n",
      "  Batch 590/1778 - Loss: 0.1986, Accuracy: 0.9268\n",
      "  Batch 600/1778 - Loss: 0.1992, Accuracy: 0.9265\n",
      "  Batch 610/1778 - Loss: 0.1989, Accuracy: 0.9265\n",
      "  Batch 620/1778 - Loss: 0.1992, Accuracy: 0.9264\n",
      "  Batch 630/1778 - Loss: 0.1985, Accuracy: 0.9268\n",
      "  Batch 640/1778 - Loss: 0.1975, Accuracy: 0.9272\n",
      "  Batch 650/1778 - Loss: 0.1982, Accuracy: 0.9268\n",
      "  Batch 660/1778 - Loss: 0.1988, Accuracy: 0.9267\n",
      "  Batch 670/1778 - Loss: 0.1989, Accuracy: 0.9265\n",
      "  Batch 680/1778 - Loss: 0.1992, Accuracy: 0.9265\n",
      "  Batch 690/1778 - Loss: 0.1985, Accuracy: 0.9269\n",
      "  Batch 700/1778 - Loss: 0.1987, Accuracy: 0.9269\n",
      "  Batch 710/1778 - Loss: 0.1990, Accuracy: 0.9267\n",
      "  Batch 720/1778 - Loss: 0.1984, Accuracy: 0.9267\n",
      "  Batch 730/1778 - Loss: 0.1986, Accuracy: 0.9268\n",
      "  Batch 740/1778 - Loss: 0.1987, Accuracy: 0.9270\n",
      "  Batch 750/1778 - Loss: 0.1985, Accuracy: 0.9269\n",
      "  Batch 760/1778 - Loss: 0.1982, Accuracy: 0.9270\n",
      "  Batch 770/1778 - Loss: 0.1975, Accuracy: 0.9272\n",
      "  Batch 780/1778 - Loss: 0.1969, Accuracy: 0.9273\n",
      "  Batch 790/1778 - Loss: 0.1973, Accuracy: 0.9272\n",
      "  Batch 800/1778 - Loss: 0.1978, Accuracy: 0.9271\n",
      "  Batch 810/1778 - Loss: 0.1974, Accuracy: 0.9273\n",
      "  Batch 820/1778 - Loss: 0.1980, Accuracy: 0.9271\n",
      "  Batch 830/1778 - Loss: 0.1976, Accuracy: 0.9272\n",
      "  Batch 840/1778 - Loss: 0.1972, Accuracy: 0.9274\n",
      "  Batch 850/1778 - Loss: 0.1976, Accuracy: 0.9273\n",
      "  Batch 860/1778 - Loss: 0.1976, Accuracy: 0.9273\n",
      "  Batch 870/1778 - Loss: 0.1978, Accuracy: 0.9270\n",
      "  Batch 880/1778 - Loss: 0.1980, Accuracy: 0.9269\n",
      "  Batch 890/1778 - Loss: 0.1974, Accuracy: 0.9270\n",
      "  Batch 900/1778 - Loss: 0.1976, Accuracy: 0.9268\n",
      "  Batch 910/1778 - Loss: 0.1979, Accuracy: 0.9267\n",
      "  Batch 920/1778 - Loss: 0.1975, Accuracy: 0.9268\n",
      "  Batch 930/1778 - Loss: 0.1978, Accuracy: 0.9266\n",
      "  Batch 940/1778 - Loss: 0.1983, Accuracy: 0.9263\n",
      "  Batch 950/1778 - Loss: 0.1981, Accuracy: 0.9264\n",
      "  Batch 960/1778 - Loss: 0.1979, Accuracy: 0.9265\n",
      "  Batch 970/1778 - Loss: 0.1974, Accuracy: 0.9267\n",
      "  Batch 980/1778 - Loss: 0.1970, Accuracy: 0.9269\n",
      "  Batch 990/1778 - Loss: 0.1974, Accuracy: 0.9269\n",
      "  Batch 1000/1778 - Loss: 0.1977, Accuracy: 0.9268\n",
      "  Batch 1010/1778 - Loss: 0.1972, Accuracy: 0.9270\n",
      "  Batch 1020/1778 - Loss: 0.1976, Accuracy: 0.9269\n",
      "  Batch 1030/1778 - Loss: 0.1975, Accuracy: 0.9271\n",
      "  Batch 1040/1778 - Loss: 0.1978, Accuracy: 0.9271\n",
      "  Batch 1050/1778 - Loss: 0.1985, Accuracy: 0.9269\n",
      "  Batch 1060/1778 - Loss: 0.1987, Accuracy: 0.9269\n",
      "  Batch 1070/1778 - Loss: 0.1980, Accuracy: 0.9271\n",
      "  Batch 1080/1778 - Loss: 0.1981, Accuracy: 0.9271\n",
      "  Batch 1090/1778 - Loss: 0.1979, Accuracy: 0.9272\n",
      "  Batch 1100/1778 - Loss: 0.1983, Accuracy: 0.9271\n",
      "  Batch 1110/1778 - Loss: 0.1987, Accuracy: 0.9269\n",
      "  Batch 1120/1778 - Loss: 0.1984, Accuracy: 0.9270\n",
      "  Batch 1130/1778 - Loss: 0.1980, Accuracy: 0.9271\n",
      "  Batch 1140/1778 - Loss: 0.1978, Accuracy: 0.9273\n",
      "  Batch 1150/1778 - Loss: 0.1974, Accuracy: 0.9274\n",
      "  Batch 1160/1778 - Loss: 0.1979, Accuracy: 0.9272\n",
      "  Batch 1170/1778 - Loss: 0.1979, Accuracy: 0.9272\n",
      "  Batch 1180/1778 - Loss: 0.1981, Accuracy: 0.9272\n",
      "  Batch 1190/1778 - Loss: 0.1981, Accuracy: 0.9273\n",
      "  Batch 1200/1778 - Loss: 0.1976, Accuracy: 0.9274\n",
      "  Batch 1210/1778 - Loss: 0.1976, Accuracy: 0.9274\n",
      "  Batch 1220/1778 - Loss: 0.1973, Accuracy: 0.9275\n",
      "  Batch 1230/1778 - Loss: 0.1971, Accuracy: 0.9278\n",
      "  Batch 1240/1778 - Loss: 0.1967, Accuracy: 0.9279\n",
      "  Batch 1250/1778 - Loss: 0.1967, Accuracy: 0.9279\n",
      "  Batch 1260/1778 - Loss: 0.1964, Accuracy: 0.9279\n",
      "  Batch 1270/1778 - Loss: 0.1964, Accuracy: 0.9278\n",
      "  Batch 1280/1778 - Loss: 0.1964, Accuracy: 0.9279\n",
      "  Batch 1290/1778 - Loss: 0.1965, Accuracy: 0.9277\n",
      "  Batch 1300/1778 - Loss: 0.1962, Accuracy: 0.9278\n",
      "  Batch 1310/1778 - Loss: 0.1962, Accuracy: 0.9278\n",
      "  Batch 1320/1778 - Loss: 0.1958, Accuracy: 0.9279\n",
      "  Batch 1330/1778 - Loss: 0.1957, Accuracy: 0.9280\n",
      "  Batch 1340/1778 - Loss: 0.1957, Accuracy: 0.9280\n",
      "  Batch 1350/1778 - Loss: 0.1959, Accuracy: 0.9281\n",
      "  Batch 1360/1778 - Loss: 0.1960, Accuracy: 0.9279\n",
      "  Batch 1370/1778 - Loss: 0.1959, Accuracy: 0.9279\n",
      "  Batch 1380/1778 - Loss: 0.1958, Accuracy: 0.9280\n",
      "  Batch 1390/1778 - Loss: 0.1957, Accuracy: 0.9281\n",
      "  Batch 1400/1778 - Loss: 0.1956, Accuracy: 0.9281\n",
      "  Batch 1410/1778 - Loss: 0.1958, Accuracy: 0.9280\n",
      "  Batch 1420/1778 - Loss: 0.1956, Accuracy: 0.9280\n",
      "  Batch 1430/1778 - Loss: 0.1956, Accuracy: 0.9279\n",
      "  Batch 1440/1778 - Loss: 0.1960, Accuracy: 0.9277\n",
      "  Batch 1450/1778 - Loss: 0.1958, Accuracy: 0.9278\n",
      "  Batch 1460/1778 - Loss: 0.1955, Accuracy: 0.9280\n",
      "  Batch 1470/1778 - Loss: 0.1960, Accuracy: 0.9279\n",
      "  Batch 1480/1778 - Loss: 0.1964, Accuracy: 0.9279\n",
      "  Batch 1490/1778 - Loss: 0.1968, Accuracy: 0.9276\n",
      "  Batch 1500/1778 - Loss: 0.1965, Accuracy: 0.9277\n",
      "  Batch 1510/1778 - Loss: 0.1964, Accuracy: 0.9277\n",
      "  Batch 1520/1778 - Loss: 0.1964, Accuracy: 0.9278\n",
      "  Batch 1530/1778 - Loss: 0.1965, Accuracy: 0.9278\n",
      "  Batch 1540/1778 - Loss: 0.1966, Accuracy: 0.9278\n",
      "  Batch 1550/1778 - Loss: 0.1963, Accuracy: 0.9279\n",
      "  Batch 1560/1778 - Loss: 0.1963, Accuracy: 0.9279\n",
      "  Batch 1570/1778 - Loss: 0.1964, Accuracy: 0.9279\n",
      "  Batch 1580/1778 - Loss: 0.1963, Accuracy: 0.9279\n",
      "  Batch 1590/1778 - Loss: 0.1962, Accuracy: 0.9280\n",
      "  Batch 1600/1778 - Loss: 0.1962, Accuracy: 0.9280\n",
      "  Batch 1610/1778 - Loss: 0.1963, Accuracy: 0.9279\n",
      "  Batch 1620/1778 - Loss: 0.1963, Accuracy: 0.9279\n",
      "  Batch 1630/1778 - Loss: 0.1962, Accuracy: 0.9279\n",
      "  Batch 1640/1778 - Loss: 0.1961, Accuracy: 0.9279\n",
      "  Batch 1650/1778 - Loss: 0.1961, Accuracy: 0.9278\n",
      "  Batch 1660/1778 - Loss: 0.1965, Accuracy: 0.9276\n",
      "  Batch 1670/1778 - Loss: 0.1966, Accuracy: 0.9276\n",
      "  Batch 1680/1778 - Loss: 0.1967, Accuracy: 0.9276\n",
      "  Batch 1690/1778 - Loss: 0.1966, Accuracy: 0.9276\n",
      "  Batch 1700/1778 - Loss: 0.1965, Accuracy: 0.9277\n",
      "  Batch 1710/1778 - Loss: 0.1962, Accuracy: 0.9277\n",
      "  Batch 1720/1778 - Loss: 0.1962, Accuracy: 0.9276\n",
      "  Batch 1730/1778 - Loss: 0.1966, Accuracy: 0.9274\n",
      "  Batch 1740/1778 - Loss: 0.1967, Accuracy: 0.9273\n",
      "  Batch 1750/1778 - Loss: 0.1969, Accuracy: 0.9273\n",
      "  Batch 1760/1778 - Loss: 0.1969, Accuracy: 0.9273\n",
      "  Batch 1770/1778 - Loss: 0.1970, Accuracy: 0.9272\n",
      "\n",
      "Kết quả Epoch 10:\n",
      "  Loss trung bình: 0.1971\n",
      "  Độ chính xác trung bình: 0.9272\n",
      "  -> Cập nhật mô hình tốt nhất.\n",
      "Hoàn tất huấn luyện.\n",
      "Mô hình và tokenizer đã được lưu tại saved_phobert_model\n",
      "\n",
      "Bắt đầu đánh giá mô hình trên tập kiểm tra...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/1186051907.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/kaggle/working/best_model.pt'))  # Tải mô hình tốt nhất\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoàn tất đánh giá.\n",
      "\n",
      "Báo cáo đánh giá:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.86118   0.84454   0.85278      2380\n",
      "           1    0.79288   0.84665   0.81888      2315\n",
      "           2    0.80796   0.76480   0.78579      2415\n",
      "           3    0.94395   0.96192   0.95285      2416\n",
      "           4    0.90139   0.89101   0.89617      2257\n",
      "           5    0.98689   0.98608   0.98648      2442\n",
      "\n",
      "    accuracy                        0.88295     14225\n",
      "   macro avg    0.88237   0.88250   0.88216     14225\n",
      "weighted avg    0.88305   0.88295   0.88272     14225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt các thư viện cần thiết\n",
    "# pip install transformers torch scikit-learn pandas\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# Thiết lập thiết bị\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Sử dụng thiết bị: {device}\")\n",
    "\n",
    "# Tải tokenizer và model PhoBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=6)\n",
    "model.to(device)\n",
    "\n",
    "# Tiền xử lý dữ liệu cho PhoBERT\n",
    "def encode_texts(texts, tokenizer, max_length=256):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "print(\"Bắt đầu mã hóa dữ liệu...\")\n",
    "X_train_enc = encode_texts(X_train, tokenizer)\n",
    "X_test_enc = encode_texts(X_test, tokenizer)\n",
    "print(\"Hoàn tất mã hóa dữ liệu.\")\n",
    "\n",
    "# Chuyển đổi nhãn thành tensor\n",
    "y_train_tensor = torch.tensor(y_train.values)\n",
    "y_test_tensor = torch.tensor(y_test.values)\n",
    "\n",
    "# Tạo DataLoader\n",
    "batch_size = 32  # Giảm batch size để tránh vấn đề về bộ nhớ GPU\n",
    "\n",
    "train_dataset = TensorDataset(X_train_enc['input_ids'], X_train_enc['attention_mask'], y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_enc['input_ids'], X_test_enc['attention_mask'], y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # Giảm learning rate từ 2e-5 xuống 1e-5\n",
    "\n",
    "num_epochs = 10  # Tăng số epoch để mô hình có thời gian học nhiều hơn\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "# Thiết lập scheduler để điều chỉnh learning rate\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Hàm tính độ chính xác\n",
    "def compute_accuracy(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(preds_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Early Stopping parameters\n",
    "patience = 2\n",
    "best_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "print(\"Bắt đầu huấn luyện mô hình...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n===== Epoch {epoch + 1} / {num_epochs} =====\")\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        model.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Tính độ chính xác trên batch hiện tại\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = labels.cpu().numpy()\n",
    "        batch_accuracy = compute_accuracy(logits, label_ids)\n",
    "        total_accuracy += batch_accuracy\n",
    "\n",
    "        loss.backward()\n",
    "        # Clip gradients để tránh gradient explosion\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if step % 10 == 0 and step != 0:\n",
    "            avg_loss = total_loss / (step + 1)\n",
    "            avg_accuracy = total_accuracy / (step + 1)\n",
    "            print(f\"  Batch {step}/{len(train_loader)} - Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "    avg_epoch_loss = total_loss / len(train_loader)\n",
    "    avg_epoch_accuracy = total_accuracy / len(train_loader)\n",
    "    print(f\"\\nKết quả Epoch {epoch + 1}:\")\n",
    "    print(f\"  Loss trung bình: {avg_epoch_loss:.4f}\")\n",
    "    print(f\"  Độ chính xác trung bình: {avg_epoch_accuracy:.4f}\")\n",
    "\n",
    "    # Đánh giá và kiểm tra Early Stopping\n",
    "    if avg_epoch_accuracy > best_accuracy:\n",
    "        best_accuracy = avg_epoch_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(\"  -> Cập nhật mô hình tốt nhất.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"  -> Không cải thiện được trong {epochs_no_improve} epoch.\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping được kích hoạt.\")\n",
    "            break\n",
    "\n",
    "print(\"Hoàn tất huấn luyện.\")\n",
    "\n",
    "# Lưu mô hình và tokenizer sử dụng save_pretrained\n",
    "save_directory = 'saved_phobert_model'\n",
    "\n",
    "# Tạo thư mục lưu nếu chưa tồn tại\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Lưu tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Mô hình và tokenizer đã được lưu tại {save_directory}\")\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "print(\"\\nBắt đầu đánh giá mô hình trên tập kiểm tra...\")\n",
    "model.load_state_dict(torch.load('/kaggle/working/best_model.pt'))  # Tải mô hình tốt nhất\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Hoàn tất đánh giá.\")\n",
    "\n",
    "print(\"\\nBáo cáo đánh giá:\")\n",
    "print(classification_report(y_true, y_pred, digits=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2594e",
   "metadata": {
    "papermill": {
     "duration": 0.14298,
     "end_time": "2024-10-16T15:16:25.575362",
     "exception": false,
     "start_time": "2024-10-16T15:16:25.432382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5885637,
     "sourceId": 9640489,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13482.033991,
   "end_time": "2024-10-16T15:16:28.442026",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-16T11:31:46.408035",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00b77fd139f84ef28d622198614e4a6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e1e0316db92d402fb2635a1716436119",
       "placeholder": "​",
       "style": "IPY_MODEL_38b78c636d90426dbf8d392f9a87d099",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "0717130112c543e2bb2938443cf096ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a543855855f4a7cb1da21ea0ee6fc3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0a88239030b14f46bb819c2360ae1605": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c5f54bbc3c742b188dc4be58b916663": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "13eca54033944a39892c0174cd60f789": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "17da8065b12449f4839ddc4aeb76249e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c66dbc50993436ea7caf90ff931f9af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4db29dad9a842a887891c2e138ac007",
       "placeholder": "​",
       "style": "IPY_MODEL_6fc395e7319840f7883a0718ffe61f92",
       "value": " 543M/543M [00:01&lt;00:00, 334MB/s]"
      }
     },
     "30d65ca82d8f4c17a0e2fdeb07d144ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "38b78c636d90426dbf8d392f9a87d099": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "47a9603813b34bf3855088830812db63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc997af34130420ea09a7e86407e66dc",
       "max": 895321.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_30d65ca82d8f4c17a0e2fdeb07d144ab",
       "value": 895321.0
      }
     },
     "48c71db9a1dc45bcb3a963859444a4fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49fed8a88c90458da9b72c54cd6a150a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_61dc642792964347aebeba7143d28da3",
       "placeholder": "​",
       "style": "IPY_MODEL_dab553baa15245e791c537102004ea1d",
       "value": "tokenizer.json: 100%"
      }
     },
     "4b1cf96fc6534166b1c1fae6fd632148": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "504d0ec072c343b48355e501d1ada37e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0717130112c543e2bb2938443cf096ad",
       "max": 1135173.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_80bbee4e748d4b64b300082890ce2e58",
       "value": 1135173.0
      }
     },
     "54cc36ead60d41b6a5e15f15da36bfc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_49fed8a88c90458da9b72c54cd6a150a",
        "IPY_MODEL_643cd4a037a84ce6b4619dfe54002551",
        "IPY_MODEL_e5df7dc944334c2bb524abcc15542e31"
       ],
       "layout": "IPY_MODEL_b5986cdddb724a7296e492324529ad9b"
      }
     },
     "560fccd5cf954cbcb5d56c21edaa2b2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "576cca6bf8584b29a1f7e816315d9851": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5abc1a066c784e83b3b175fecdd6169b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00b77fd139f84ef28d622198614e4a6e",
        "IPY_MODEL_a06250e3cf3a41889ad9b8e4fb7a416b",
        "IPY_MODEL_2c66dbc50993436ea7caf90ff931f9af"
       ],
       "layout": "IPY_MODEL_bc27e622527d41818585b3203d79c8fe"
      }
     },
     "5b9b701cad4344ebb4dbd87b0fa5a4f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "61dc642792964347aebeba7143d28da3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "643cd4a037a84ce6b4619dfe54002551": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4b1cf96fc6534166b1c1fae6fd632148",
       "max": 3132320.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_576cca6bf8584b29a1f7e816315d9851",
       "value": 3132320.0
      }
     },
     "650052d47a9f49fa8f2c237ad93a7774": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d2a06d17480b4f379f44786e869eb604",
        "IPY_MODEL_504d0ec072c343b48355e501d1ada37e",
        "IPY_MODEL_f8eb2436d1824c8e84c354d94678ebf3"
       ],
       "layout": "IPY_MODEL_fc9ca2b943a840fa962229d472948df1"
      }
     },
     "66c18f0f633a445d842e4044e485ca84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69e7a188520b4115baada1433ae899f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ef714a3766304c98849ae5d4c9b970d7",
        "IPY_MODEL_6b95c6e2643a4cf5838d30242c3f1291",
        "IPY_MODEL_a4ebc44d8f9244a7b24a27db9e977644"
       ],
       "layout": "IPY_MODEL_e0581fc81a9543eabff15b5e33148033"
      }
     },
     "6b95c6e2643a4cf5838d30242c3f1291": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ee366ac017db41eeb4c38c737904e1fb",
       "max": 557.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a543855855f4a7cb1da21ea0ee6fc3b",
       "value": 557.0
      }
     },
     "6ee10da92960491ca7e51467438ce74a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0c5f54bbc3c742b188dc4be58b916663",
       "placeholder": "​",
       "style": "IPY_MODEL_8813f925f9484c0ea765e831f64b8a32",
       "value": " 71121/71121 [02:56&lt;00:00, 328.33it/s]"
      }
     },
     "6fc395e7319840f7883a0718ffe61f92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "769b5aefa6b84f9d9b462276f903d86b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80bbee4e748d4b64b300082890ce2e58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "83bb8c8bf6274fcc97b31c2b49e11997": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad3b10d75e834157a860973c4ce12748",
       "placeholder": "​",
       "style": "IPY_MODEL_5b9b701cad4344ebb4dbd87b0fa5a4f3",
       "value": " 895k/895k [00:00&lt;00:00, 3.36MB/s]"
      }
     },
     "87e2b84752c14dcb84fb69fac376a961": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8813f925f9484c0ea765e831f64b8a32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "89b7f4c4b7284afca4267aa8eed5839c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "957e45b563954552ad715aee5b94ba01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_66c18f0f633a445d842e4044e485ca84",
       "max": 71121.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_befddd89213a4b86998a3ca6efc0e7c1",
       "value": 71121.0
      }
     },
     "9aaa082b41c1489c90f5e654ea63cae5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a06250e3cf3a41889ad9b8e4fb7a416b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fbb49cbd7fad4427aea4656b096c4e20",
       "max": 542923308.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_13eca54033944a39892c0174cd60f789",
       "value": 542923308.0
      }
     },
     "a49b5617dcca4f0785d39c36b4d95475": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4ebc44d8f9244a7b24a27db9e977644": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d6d297f0fbab49399dc8fe1dd8ca86aa",
       "placeholder": "​",
       "style": "IPY_MODEL_f8534d750d1e4a59bb74a277e7c1750e",
       "value": " 557/557 [00:00&lt;00:00, 43.0kB/s]"
      }
     },
     "ad3b10d75e834157a860973c4ce12748": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5986cdddb724a7296e492324529ad9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb39d18dbdaf41c1acfcfe26601fa443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0b4b368f8244e86a23bb39b4cdc5254",
        "IPY_MODEL_957e45b563954552ad715aee5b94ba01",
        "IPY_MODEL_6ee10da92960491ca7e51467438ce74a"
       ],
       "layout": "IPY_MODEL_0a88239030b14f46bb819c2360ae1605"
      }
     },
     "bc27e622527d41818585b3203d79c8fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc997af34130420ea09a7e86407e66dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "befddd89213a4b86998a3ca6efc0e7c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bf63eac022d04733965950cbbd02d7f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c7cf508e8d674ba1b9995088dd2d6bb1",
        "IPY_MODEL_47a9603813b34bf3855088830812db63",
        "IPY_MODEL_83bb8c8bf6274fcc97b31c2b49e11997"
       ],
       "layout": "IPY_MODEL_48c71db9a1dc45bcb3a963859444a4fa"
      }
     },
     "c7cf508e8d674ba1b9995088dd2d6bb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87e2b84752c14dcb84fb69fac376a961",
       "placeholder": "​",
       "style": "IPY_MODEL_9aaa082b41c1489c90f5e654ea63cae5",
       "value": "vocab.txt: 100%"
      }
     },
     "cfe3c1c7d40b46a1a776460f8a42b704": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d0b4b368f8244e86a23bb39b4cdc5254": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d35f2daacea74e2a827839c87447d509",
       "placeholder": "​",
       "style": "IPY_MODEL_cfe3c1c7d40b46a1a776460f8a42b704",
       "value": "100%"
      }
     },
     "d2a06d17480b4f379f44786e869eb604": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a49b5617dcca4f0785d39c36b4d95475",
       "placeholder": "​",
       "style": "IPY_MODEL_89b7f4c4b7284afca4267aa8eed5839c",
       "value": "bpe.codes: 100%"
      }
     },
     "d35f2daacea74e2a827839c87447d509": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4db29dad9a842a887891c2e138ac007": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5948e5c1f0c4483a3fcf3a562f088f7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6d297f0fbab49399dc8fe1dd8ca86aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dab553baa15245e791c537102004ea1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dc4525a769454b84aa763119a5d99a62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd91ffd59e2d4c0780ab20b95fe30e0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e0581fc81a9543eabff15b5e33148033": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1e0316db92d402fb2635a1716436119": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5df7dc944334c2bb524abcc15542e31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_17da8065b12449f4839ddc4aeb76249e",
       "placeholder": "​",
       "style": "IPY_MODEL_769b5aefa6b84f9d9b462276f903d86b",
       "value": " 3.13M/3.13M [00:00&lt;00:00, 25.2MB/s]"
      }
     },
     "ee366ac017db41eeb4c38c737904e1fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef714a3766304c98849ae5d4c9b970d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dc4525a769454b84aa763119a5d99a62",
       "placeholder": "​",
       "style": "IPY_MODEL_dd91ffd59e2d4c0780ab20b95fe30e0a",
       "value": "config.json: 100%"
      }
     },
     "f8534d750d1e4a59bb74a277e7c1750e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f8eb2436d1824c8e84c354d94678ebf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d5948e5c1f0c4483a3fcf3a562f088f7",
       "placeholder": "​",
       "style": "IPY_MODEL_560fccd5cf954cbcb5d56c21edaa2b2c",
       "value": " 1.14M/1.14M [00:00&lt;00:00, 17.0MB/s]"
      }
     },
     "fbb49cbd7fad4427aea4656b096c4e20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc9ca2b943a840fa962229d472948df1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
